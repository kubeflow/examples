{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/WA_Fn-UseC_-Telco-Customer-Churn.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO: 194387\n",
      "YES: 33603\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle5 as pkl\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def import_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "df = import_dataset(\"https://raw.githubusercontent.com/ajinkya933/examples-1/master/telco-kaggle-competition/data/WA_Fn-UseC_-Telco-Customer-Churn.csv\") \n",
    "\n",
    "# df=pd.read_csv(\"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# for col in df.columns:\n",
    "#     print(col, \" : \",df[col].isna().sum())\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "#  look into uniques elements for every column\n",
    "df.apply(lambda x: x.unique())\n",
    "df.apply(lambda x: x.unique())\n",
    "\n",
    "#  \"No\" and \"No internet service\" has no meaning to stay toghether so I will repalce them with \"No\"\n",
    "df[\"OnlineSecurity\"] = df[\"OnlineSecurity\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"OnlineBackup\"] = df[\"OnlineBackup\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"DeviceProtection\"] = df[\"DeviceProtection\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"TechSupport\"] = df[\"TechSupport\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"StreamingTV\"] = df[\"StreamingTV\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"StreamingMovies\"] = df[\"StreamingMovies\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "\n",
    "# Same for \"No phone service\"\n",
    "df[\"MultipleLines\"] = df[\"MultipleLines\"].apply(lambda x: x.replace(\"No phone service\", \"No\"))\n",
    "\n",
    "df.apply(lambda x: x.unique())\n",
    "\n",
    "df.drop(columns=[\"customerID\"], axis=1, inplace=True)\n",
    "\n",
    "no=df[df[\"Churn\"]==\"No\"][\"tenure\"]\n",
    "yes=df[df[\"Churn\"]==\"Yes\"][\"tenure\"]\n",
    "\n",
    "print(\"NO:\", df[df[\"Churn\"]==\"No\"][\"tenure\"].sort_values().sum())\n",
    "print(\"YES:\",df[df[\"Churn\"]==\"Yes\"][\"tenure\"].sort_values().sum())\n",
    "\n",
    "df.apply(lambda x: x.unique())\n",
    "\n",
    "#  In a new df I will replace no with 0, yest with 1\n",
    "#  InternetService will not be touched at this moment\n",
    "\n",
    "# \n",
    "dfx=df.copy()\n",
    "dfx.drop(\"InternetService\", axis=1, inplace=True)\n",
    "dfx.columns\n",
    "\n",
    "dfx.replace(\"No\", 0, inplace=True)\n",
    "dfx.replace(\"Yes\", 1, inplace=True)\n",
    "\n",
    "dfx.apply(lambda x: x.unique())\n",
    "dfx[\"InternetService\"] = df[\"InternetService\"] \n",
    "dfx[\"gender\"].replace(\"Female\", 0, inplace=True)\n",
    "dfx[\"gender\"].replace(\"Male\", 1, inplace=True)\n",
    "\n",
    "# Label Encoding\n",
    "\n",
    "\n",
    "# I will Use LabelEncoder instead of the most common pd.get_dummies() because i will have less features at the end\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "\n",
    "for col in dfx.columns:\n",
    "    if dfx[col].dtypes == \"object\":\n",
    "        dfx[col]=le.fit_transform(dfx[col])\n",
    "        \n",
    "# dfx.head()\n",
    "\n",
    "dfx.apply(lambda x: x.unique())\n",
    "\n",
    "# Float columns must be scaled\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms=MinMaxScaler()\n",
    "\n",
    "dfx[\"TotalCharges\"] = mms.fit_transform(np.array(dfx[\"TotalCharges\"]).reshape(-1, 1))\n",
    "dfx[\"MonthlyCharges\"] = mms.fit_transform(np.array(dfx[\"MonthlyCharges\"]).reshape(-1, 1))\n",
    "dfx[\"tenure\"] = mms.fit_transform(np.array(dfx[\"tenure\"]).reshape(-1, 1))\n",
    "\n",
    "#  Split the df for ML\n",
    "#  I'm looking to predict the Churn colum\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dfx.drop(\"Churn\", axis=1)\n",
    "y = dfx[\"Churn\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 101)\n",
    "\n",
    "#to save it\n",
    "with open(\"data/train.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_train, y_train], f)\n",
    "\n",
    "with open(\"data/test.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_test, y_test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zf/rspfh96d5h7bpk6k8hr6b6pc0000gn/T/ipykernel_3904/3258610814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# with open(\"data/train.pkl\", \"rb\") as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     X_train, y_train = pkl.load(f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoordination_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so, 0x0002): Library not loaded: @rpath/_pywrap_tensorflow_internal.so\n  Referenced from: /Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tfe.so\n  Reason: tried: '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utfe.so___Utensorflow/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../../_solib_darwin_x86_64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/../_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/lib/_pywrap_tensorflow_internal.so' (no such file), '/Users/ajinkyabobade/opt/anaconda3/bin/../lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/local/lib/_pywrap_tensorflow_internal.so' (no such file), '/usr/lib/_pywrap_tensorflow_internal.so' (no such file)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "\n",
    "with open(\"/data/train.pkl\", \"rb\") as f:\n",
    "    X_train, y_train = pkl.load(f)\n",
    "\n",
    "with open(\"/data/test.pkl\", \"rb\") as f:\n",
    "    X_test, y_test = pkl.load(f)\n",
    "\n",
    "model = ks.Sequential(\n",
    "    [\n",
    "        ks.layers.Dense(25,input_shape=(19,), activation=\"relu\"),\n",
    "        ks.layers.Dense(20, activation=\"relu\"),\n",
    "        ks.layers.Dense(15, activation=\"relu\"),\n",
    "        ks.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\", # I'm looking for 0 and 1 response\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_model.fit(X_train,y_train)\n",
    "joblib.dump(ideal_model, \"/data/ideal_model.joblib\")\n",
    "\n",
    "print(ideal_model.best_params_)\n",
    "\n",
    "\n",
    "print(show_scores(ideal_model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d29e9e904a2dad5dfa2f8d860be8708ce2b2e36d95c2386a43b5cbb7aa73861b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
