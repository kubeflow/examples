{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO: 194387\n",
      "YES: 33603\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pickle as pkl\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def import_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "df = import_dataset(\"https://raw.githubusercontent.com/ajinkya933/examples-1/master/telco-kaggle-competition/data/WA_Fn-UseC_-Telco-Customer-Churn.csv\") \n",
    "\n",
    "# df=pd.read_csv(\"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# for col in df.columns:\n",
    "#     print(col, \" : \",df[col].isna().sum())\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "#  look into uniques elements for every column\n",
    "df.apply(lambda x: x.unique())\n",
    "df.apply(lambda x: x.unique())\n",
    "\n",
    "#  \"No\" and \"No internet service\" has no meaning to stay toghether so I will repalce them with \"No\"\n",
    "df[\"OnlineSecurity\"] = df[\"OnlineSecurity\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"OnlineBackup\"] = df[\"OnlineBackup\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"DeviceProtection\"] = df[\"DeviceProtection\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"TechSupport\"] = df[\"TechSupport\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"StreamingTV\"] = df[\"StreamingTV\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "df[\"StreamingMovies\"] = df[\"StreamingMovies\"].apply(lambda x: x.replace(\"No internet service\", \"No\"))\n",
    "\n",
    "# Same for \"No phone service\"\n",
    "df[\"MultipleLines\"] = df[\"MultipleLines\"].apply(lambda x: x.replace(\"No phone service\", \"No\"))\n",
    "\n",
    "df.apply(lambda x: x.unique())\n",
    "\n",
    "df.drop(columns=[\"customerID\"], axis=1, inplace=True)\n",
    "\n",
    "no=df[df[\"Churn\"]==\"No\"][\"tenure\"]\n",
    "yes=df[df[\"Churn\"]==\"Yes\"][\"tenure\"]\n",
    "\n",
    "print(\"NO:\", df[df[\"Churn\"]==\"No\"][\"tenure\"].sort_values().sum())\n",
    "print(\"YES:\",df[df[\"Churn\"]==\"Yes\"][\"tenure\"].sort_values().sum())\n",
    "\n",
    "df.apply(lambda x: x.unique())\n",
    "\n",
    "#  In a new df I will replace no with 0, yest with 1\n",
    "#  InternetService will not be touched at this moment\n",
    "\n",
    "# \n",
    "dfx=df.copy()\n",
    "dfx.drop(\"InternetService\", axis=1, inplace=True)\n",
    "dfx.columns\n",
    "\n",
    "dfx.replace(\"No\", 0, inplace=True)\n",
    "dfx.replace(\"Yes\", 1, inplace=True)\n",
    "\n",
    "dfx.apply(lambda x: x.unique())\n",
    "dfx[\"InternetService\"] = df[\"InternetService\"] \n",
    "dfx[\"gender\"].replace(\"Female\", 0, inplace=True)\n",
    "dfx[\"gender\"].replace(\"Male\", 1, inplace=True)\n",
    "\n",
    "# Label Encoding\n",
    "\n",
    "\n",
    "# I will Use LabelEncoder instead of the most common pd.get_dummies() because i will have less features at the end\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "\n",
    "for col in dfx.columns:\n",
    "    if dfx[col].dtypes == \"object\":\n",
    "        dfx[col]=le.fit_transform(dfx[col])\n",
    "        \n",
    "# dfx.head()\n",
    "\n",
    "dfx.apply(lambda x: x.unique())\n",
    "\n",
    "# Float columns must be scaled\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms=MinMaxScaler()\n",
    "\n",
    "dfx[\"TotalCharges\"] = mms.fit_transform(np.array(dfx[\"TotalCharges\"]).reshape(-1, 1))\n",
    "dfx[\"MonthlyCharges\"] = mms.fit_transform(np.array(dfx[\"MonthlyCharges\"]).reshape(-1, 1))\n",
    "dfx[\"tenure\"] = mms.fit_transform(np.array(dfx[\"tenure\"]).reshape(-1, 1))\n",
    "\n",
    "#  Split the df for ML\n",
    "#  I'm looking to predict the Churn colum\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dfx.drop(\"Churn\", axis=1)\n",
    "y = dfx[\"Churn\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 101)\n",
    "\n",
    "#to save it\n",
    "with open(\"data/train.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_train, y_train], f)\n",
    "\n",
    "with open(\"data/test.pkl\", \"wb\") as f:\n",
    "    pkl.dump([X_test, y_test], f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "165/165 [==============================] - 1s 1ms/step - loss: 0.5267 - accuracy: 0.7209\n",
      "Epoch 2/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7763\n",
      "Epoch 3/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7857\n",
      "Epoch 4/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7871\n",
      "Epoch 5/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7929\n",
      "Epoch 6/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7922\n",
      "Epoch 7/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.7952\n",
      "Epoch 8/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.8013\n",
      "Epoch 9/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.7994\n",
      "Epoch 10/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ddff00e20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "\n",
    "with open(\"data/train.pkl\", \"rb\") as f:\n",
    "    X_train, y_train = pkl.load(f)\n",
    "\n",
    "with open(\"data/test.pkl\", \"rb\") as f:\n",
    "    X_test, y_test = pkl.load(f)\n",
    "\n",
    "model = ks.Sequential(\n",
    "    [\n",
    "        ks.layers.Dense(25,input_shape=(19,), activation=\"relu\"),\n",
    "        ks.layers.Dense(20, activation=\"relu\"),\n",
    "        ks.layers.Dense(15, activation=\"relu\"),\n",
    "        ks.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\", # I'm looking for 0 and 1 response\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41681215167045593, 0.8145620226860046]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d29e9e904a2dad5dfa2f8d860be8708ce2b2e36d95c2386a43b5cbb7aa73861b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
