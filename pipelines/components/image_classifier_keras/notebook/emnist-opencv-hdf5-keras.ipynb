{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Demonstration for Computer Vision / Grayscale - EMNIST\n",
    "\n",
    "This demonstration will use the EMNIST dataset. This is a dataset that is an extension of the MNIST (handwritten digits). It is derived from the NIST Special Dataset 19 for handwritten lower and uppercase characters and digits; thus consisting of 62 categories (vs. 10 in MNIST). The dataset consists of 800K images (vs. 70K for MNIST). \n",
    "\n",
    "The images in this version of EMNIST have been prepared in a similar method popularized by Yan Lecun method for the NIST MNIST dataset. In his method, the orignal images were upsampled from 20x20 to 28x28 and anti-aliased.  The original images of the NIST Special Dataset 19 in this method where downsampled from 128x128 to 28x28 using openCV INTER_AREA interpolation, which gives good results at minimizing artificats when downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequistes\n",
    "\n",
    "The following needs to be pre-installed:\n",
    "\n",
    "        openCV : pip install opencv-python\n",
    "        numpy  : pip install numpy\n",
    "        ipynb  : pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Dataset\n",
    "\n",
    "The EMNIST dataset will need to be downloaded to the same directory (folder) as this notebook.\n",
    "\n",
    "A zip file (compressed) of the dataset can be obtained at this location:\n",
    "\n",
    "https://pantheon.corp.google.com/storage/browser/cloud-samples-data/air/emnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline Chain\n",
    "\n",
    "The following ML Pipelines will be chained together for this demonstration\n",
    "\n",
    "        emnist -> openCV -> hdf5 -> model_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Image Files into Machine Learning Data using OpenCV module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the openCV ML pipeline\n",
    "import openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the on-disk set of images to in-memory set of machine learning ready data\n",
    "dataset = openCV.load_directory('emnist', colorspace=openCV.GRAYSCALE, resize=(28,28), flatten=False, concurrent=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset should be 62 collections (26 lowercase letters, 26 uppercase letters, 10 digits)  \n",
    "Each collection should consist of a set of three entries: data, labels, and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Number of collections:\", len(dataset) )\n",
    "print( \"Number of sets in a collection:\", len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first collection should have the label (letter) 'Z' and consist of 2698 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of images:\", len(dataset[0][0]))\n",
    "print(\"Label for collection:\", dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Preprocessed Image\", dataset[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Machine Learning Ready (preprocessed images) data into HDF5 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the HDF5 storage ML pipeline\n",
    "import hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the machine learning ready data to HDF5\n",
    "hdf5.store_dataset('emnist', dataset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"HDF5 file size:\", int( os.path.getsize('emnist.h5') / (1024 * 1024) ), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct CNN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras CNN Model ML pipeline\n",
    "import model_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a CNN with input layer of NN of:\n",
    "# Convolutional Layer of 32 filters with input vector (28, 28, 1)\n",
    "# Convolutional Layer of 64 filters\n",
    "# Neural Network Layer of 128 nodes and 0.50% dropout\n",
    "# Nerual Network Layer of 64 nodes\n",
    "# Output Layer with 62 nodes (classes)\n",
    "model = model_keras.construct_cnn( (28, 28, 1), 62, n_filters=(32, 64), n_nodes=(128, 64), dropout=(0.50,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset back into memory\n",
    "collections, labels, classes = hdf5.load_dataset('emnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images\", type(collections), len(collections))\n",
    "print(\"Labels\", type(labels), len(labels))\n",
    "print(\"Classes\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training (in verbose mode), each epoch will output the current accuracy on the training data (acc) and accuracy on the testing data (val_acc).\n",
    "\n",
    "*Best Practices*\n",
    "1. Once the value of val_acc levels off (stops improving) you should stop training; otherwise the model may overfit.\n",
    "\n",
    "2. If there is a high value for acc and low value for val_acc, the model is likely overfitted. Things to try:\n",
    "        A. Add higher dropout or dropout to more layers.\n",
    "        B. Reduce the number of nodes.\n",
    "        \n",
    "3. If you increase the batch size, the training time per epoch is reduced. Common practice is to set (mini) batch sizes between 32 and 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "accuracy = model_keras.train_cnn(model, collections, labels, epochs=10, batch_size=256, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('emnist.model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
