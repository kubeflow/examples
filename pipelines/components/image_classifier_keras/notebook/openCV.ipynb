{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Date Preprocessing of Images for DNN/CNN\n",
    "\n",
    "This 'ML pipeline' module uses openCV in Python to preprocess images for a Deep Neural Network (DNN) or Convoluntional Neural Network (CNN).\n",
    "\n",
    "*Prerequites*\n",
    "\n",
    "1. Images must be grayscale (single channel), RGB or BGR (three channel color) or RGBA (+alpha channel).\n",
    "2. Images must be 8 bits per pixel (bpp), but all images must be of the same bits per pixel.\n",
    "3. Images may be a mix of size and colorspace.\n",
    "4. Each image must have a single classification (i.e., label)\n",
    "5. Images may be in JPG, BMP, PNG, TIF formats.\n",
    "6. Images must be read in from disk.\n",
    "7. You must have enough memory to load all the images\n",
    "\n",
    "*Not Supported*\n",
    "\n",
    "1. 12 bit per pixel (such as electronmicrospy), and 16 bits per pixel (high color range ~ gamut).\n",
    "2. CMYK colorspace\n",
    "\n",
    "*Image Preprocessing*\n",
    "1. Conversion: Select Color vs. Gray Scale  \n",
    "2. Resize: Select Size  \n",
    "3. Normalization: Select Normalization method  \n",
    "4. Output:  \n",
    "    A) Select vector format (1D -> DNN, 2D -> CNN)   \n",
    "    B) Select data type (float16 or float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This module uses the following libraries:\n",
    "\n",
    "        numpy           - in-memory arrays\n",
    "        cv2             - image manipulation (openCV, version 2)\n",
    "        multiprocessing - concurrent processing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Functions\n",
    "\n",
    "This module has the following support functions:\n",
    "\n",
    "`image_input()`     -  Read image in from disk, perform any colorspace conversion.  \n",
    "`image_resize()`    -  Perform any resizing (downsampling) of image.  \n",
    "`image_normalize()` -  Perform normalization of pixel values.    \n",
    "`load_files()`      -  Perform processing of images for a collection (same label).  \n",
    "`load_directory()`  -  Perform processing of collections (dataset) laid out in a directory/subdirectory structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Input and Conversion (image_input)\n",
    "\n",
    "1. Read image in from a file into raw pixel format using openCV.\n",
    "2. Convert to either color or grayscale when read in.\n",
    "\n",
    "A color image consists of three or more channels (i.e., color planes), while a grayscale image consists of a single channel. Each additional channel requires more in-memory space, larger input vector and neural network, and longer to train. For example, a 100x100 (height x width) grayscale image when decompressed into raw pixel data is 10,000 bytes (at 8 bits per pixel). The same color image, which has three 100x100 color planes, when decompressed into raw pixel data is 3,000 bytes.\n",
    "\n",
    "OpenCV uses the CCIR 601 formula for converting RGB to grayscale:\n",
    "\n",
    "(0.299 * Red) + (0.587 * Green) + (0.114 * Blue)\n",
    "\n",
    "*Best Practice*\n",
    "\n",
    "Grayscale is sufficient for training recognition of objects which are 2D in nature, such as handwritting, and sketching. Typically, color, texture, etc does not contribute to the human or machine identification of the object. These objects are generally recognized by their shape (edge detection).\n",
    "\n",
    "All other forms of object classification tend to do better with color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAYSCALE = cv2.IMREAD_GRAYSCALE\n",
    "COLOR     = cv2.IMREAD_COLOR\n",
    "\n",
    "def image_input(file, colorspace=COLOR):\n",
    "    \"\"\" Read an image in from disk and convert to specified color space.\n",
    "    Args:\n",
    "        file      : (str) file path to the image.\n",
    "        colorspace: (int) the openCV flag for colorspace conversion.\n",
    "\n",
    "    Returns:\n",
    "        Uncompressed 'color converted' raw pixel data as numpy array\n",
    "        \n",
    "    Raises:\n",
    "        Exception: could not read in image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return cv2.imread(file, colorspace)\n",
    "    except:\n",
    "        raise Exception('image_input(): could not read in image: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize (image_resize)\n",
    "\n",
    "Resize performs downsampling from a higher resolution to a lower resolution image. At a lower resolution, the input vector is smaller and the number of neurons/layers needed is less. \n",
    "\n",
    "*Best Practice*\n",
    "\n",
    "At high resolutions, images have more pixel information than what's needed to train a model. The more pixel data that is retained, the bigger the input vector, memory footprint and time needed to train. Best practice is to determine the minimum size of the input vector to get the desired result, and resize the images accordingly.\n",
    "\n",
    "When downsampling, cv2.INTER_AREA and cv2.INTER_NEAREST methods produce the least artificats.\n",
    "When upsampling, cv2.INTER_LINEAR, cv2.INTER_CUBIC and cv2.INTER_LANCZOS4 methods will produce the smoothest edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, resize=(128,128), flatten=False):\n",
    "    \"\"\" Resize (downsample) an image for the target neural network\n",
    "    Args:\n",
    "        image : (numpy) an image in raw pixel data\n",
    "        resize: (tuple(int, int)) the new size of the image specified as (height, width)\n",
    "    Returns:\n",
    "        The resized image as raw pixel data as numpy array\n",
    "        \n",
    "    Raises:\n",
    "        Exception: Could not resize the image.\n",
    "    \"\"\"\n",
    "    # size must be of type set and length two (i.e., (H, W))\n",
    "    try:\n",
    "        if flatten:\n",
    "            return cv2.resize(image, resize, interpolation=cv2.INTER_AREA).flatten()\n",
    "        return cv2.resize(image, resize, interpolation=cv2.INTER_AREA)\n",
    "    except Exception as e:\n",
    "        raise Exception('image_resize(): could not resize image to: ' + str(resize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Normalizing pixel data is used to smooth out the dynamic range of pixel information, lowering noise and generally decreases the time that it takes a neural network to converge to a desired accuracy.\n",
    "\n",
    "There are three common techniques for pixel normalization:\n",
    "\n",
    "    Normalization between 0 and 1  : (x - x.min()) / (x.max() - x.min())         \n",
    "    Normalization between -1 and 1 : 2*(x - x.min()) / (x.max() - x.min()) - 1    \n",
    "    Standardization, with mean at 0: (x - x.mean()) / x.std()                      \n",
    "    \n",
    "The first two normalization methods above can be performed fast, while the third (standardization) requires more compute time.\n",
    "\n",
    "*Best Practice*  \n",
    "\n",
    "Normalization using 0..1, or -1..1 range are generally sufficient for grayscale images. Color images tend to have a far more dynanic range and generally standardization produces a better result.\n",
    "\n",
    "To achieve best perform, if there is sufficient memory, the normalization step should be applied as a one-time operation across all the images, vs. one at a time. Generally, numpy multi-dimensional arrays are used for in-memory array of matrices (continuous bytes), in which byte access and matrix operations will be the most efficient.\n",
    "\n",
    "### Input Vector\n",
    "\n",
    "Neural networks such as a DNN or FCNN take input as a 1D vector (sometimes referred to as flat). A CNN takes as input a matrix (i.e., multi-dimensional tensor). Additionally, the data type of the pixel information will effect the in-memory space and compute time when training weights. Typically, the datatype is float32 (4 bytes per pixel).\n",
    "\n",
    "In principle, float16 (i.e., half float) would be preferable in that it reduces the memory space by 50% and if there is hardware support for native half float matrix operations the compute time is reduced by approxiamtely 75%.\n",
    "\n",
    "During backward probagation, tiny numbers (less than one) are going to be multiple by each other. As these multiplications are probagated it could reach a point where the number is so small that the hardware cannot represent the number anymore. This is known as the vanishing gradient.\n",
    "\n",
    "*Best Practice*\n",
    "\n",
    "A half float should only be used if either: the number of layers is very small, or the hardware supports stochastic gradient rounding. In the later, the hardware will detect dot product matrix operations that would result in zero (vanishing gradient) and replace with a random tiny value (as in some NIVIDIA GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL_0_1  = 0\n",
    "NORMAL_N1_1 = 1\n",
    "STANDARD    = 2\n",
    "\n",
    "def image_normalization(images, normal=NORMAL_0_1, datatype=np.float32):\n",
    "    \"\"\" Normalize the pixel values of a collection of images.\n",
    "    Args:\n",
    "        images  : (numpy) collection of images in raw pixel data as a numpy array of matrices (each corresponding to an image)\n",
    "        normal  : (int) flag for selecting the normalization method\n",
    "        datatype: (type) the datatype to convert the raw pixel data to\n",
    "    Returns:\n",
    "        A collection of normalized images as a numpy array of matrices (each corresponding to an image).\n",
    "    Raises:\n",
    "        ValueError: Invalid value for normal.\n",
    "    \"\"\"\n",
    "    # This normalizes (scales pixel values) between the range 0 .. 255\n",
    "    images = images.astype(datatype)\n",
    "    if normal == NORMAL_0_1:\n",
    "        images /= 255.0\n",
    "    # This normalizes (scales pixel values) between the range -128 .. 127\n",
    "    elif normal == NORMAL_N1_1:\n",
    "        images = images / 127.5 - 1\n",
    "    # This uses standardization, where pixel are scaled with a mean of 0 and standard deviation of 1\n",
    "    elif normal == STANDARD:\n",
    "        images = (images - images.mean()) / np.std(images)\n",
    "        # the 1e-5 is to add a tiny amount to prevent the possibility of dividing by zero.\n",
    "        #images = (images - images.mean()) / np.sqrt(images.var() + 1e-5)\n",
    "    else:\n",
    "        raise ValueError('normalization(): invalid parameter for normal: ' + str(normal))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader\n",
    "\n",
    "The load_directory() routine loads a collection of images from disk to be preprocessed for training a neural network. There are many possible directory/file layout for training images. This module supports a popular and commonly seen layout as follows:\n",
    "\n",
    "                                    root_dir  \n",
    "                                    /   |   \\\n",
    "                                        V\n",
    "                                    \n",
    "            subdir_class1          subdir_class2 ...              subdir_classN\n",
    "              /  |  \\\n",
    "                 V\n",
    "        image1 image2 ... imageN\n",
    "        \n",
    "In this layout, the toplevel (root directory) is the parent of the collection. Underneath it are a plurality of subdirectories. Each subdirectory represents a unique class (label) of images. For example, if the collection was for cats and dogs, one subdirectory would be for 'cats' and the other for 'dogs'. Under each subdirectory are the images that correspond to the subdirectory's class.\n",
    "\n",
    "\n",
    "The load_directory() module performs the following steps:\n",
    "    1. Takes as input the root (parent) directory and verifies the layout.\n",
    "    2. For each subdirectory (class), process the group of images under the subdirectory.\n",
    "    3. For each subdirectory (class), assemble a prepared dataset (processed image data and labels) for a neural network.\n",
    "    \n",
    "*Best Practices*\n",
    "\n",
    "For balancing, each class (subdirectory) should have roughly an equal number of images. If unbalanced, a bias maybe introduced into the trained model. For example, if 90% of the images are cats and 10% are dogs, the trained model will likely predict all dogs as cats.\n",
    "\n",
    "Angle, lighting and perspective maybe important dependent on the deployed application. While image augmentation is popular, it's incorrect usage can lead to deployed models incorrectly (false positives) identifying objects. For example, if the deployed model is for a fixed positioned camera overlooking a conveyour belt, and the training included perspective changes, wide lighting variance, hue variance, and grainness, the model may inadvertently learn 'noise' as part of the identification. In the deployed version, toss something on the conveyour belt that does not belong there and the model may misidentify it (false positive).\n",
    "\n",
    "While these techniques prevent overfitting through generalization, the counter is the increase likelihood of false positives. Only use images (and image augmentation) that reflect the actual image input conditions of the deployed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(files, colorspace=COLOR, resize=(128,128), normal=NORMAL_0_1, flatten=False, datatype=np.float32, label=None):\n",
    "    \"\"\" Load a list of file paths and preprocess as images for a nerual network.\n",
    "    Args:\n",
    "        files     : (list(str)) a list of files paths of images (of the same classification).\n",
    "        colorspace: (int) the openCV flag for colorspace conversion\n",
    "        resize    : (tuple(int, int)) the new size of the image specified as (height, width)\n",
    "        normal    : (int) flag for selecting the normalization method\n",
    "        flatten   : (bool) flag for selecting to flatten into 1D vector (True)\n",
    "        datatype  : (type) the datatype to convert the raw pixel data to\n",
    "        label     : (str) the label (class) associated with the files (collection)\n",
    "\n",
    "    Returns:\n",
    "        A collection of images as a numpy array of matrices (each corresponding to an image) ready for feeding\n",
    "        into the input vector of a neural network, and a list of errors for (if) any image failed to be processed.\n",
    "        \n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    errors = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Read in an image from disk\n",
    "            image = image_input(file, colorspace)\n",
    "            # Resize the image for the target neural network\n",
    "            images.append(image_resize(image, resize, flatten))\n",
    "        except Exception as e:\n",
    "            # Skip processing this image,\n",
    "            # Keep a list of the images that failed to process and reason why\n",
    "            errors.append( (file, e) )\n",
    "    \n",
    "    try:\n",
    "        # Convert list of images into numpy multidimensional array\n",
    "        images = np.asarray(images)\n",
    "        # Normalize the images\n",
    "        images = image_normalization(images, normal, datatype)\n",
    "    except Exception as e:\n",
    "        # this is a critical (unrecoverable) error\n",
    "        return None, label, errors\n",
    "    \n",
    "    # Assemble a multidimensional numpy array of input vectors for this list of files.\n",
    "    return images, label, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "\n",
    "def load_directory(dir, colorspace=COLOR, resize=(128,128), normal=NORMAL_0_1, flatten=False, datatype=np.float32, concurrent=1, verbose=False):\n",
    "    \"\"\" Load and Process a dataset of images for training a neural network.\n",
    "    Args:\n",
    "        dir       : (str) A directory structure of images, where subfolders are the classes.\n",
    "        colorspace: (int) the openCV flag for colorspace conversion.\n",
    "        resize    : (tuple(int, int)) the new size of the image specified as (height, width).\n",
    "        normal    : (int) flag for selecting the normalization method.\n",
    "        flatten   : (bool) flag for selecting to flatten into 1D vector (True).\n",
    "        datatype  : (type) the datatype to convert the raw pixel data to.\n",
    "        concurrent: (int) the number of collections to process in parallel.\n",
    "        verbose   : (bool) flag to display to console progress, warnings and errors.\n",
    "    \n",
    "    Returns:\n",
    "        A list of tuples, where each tuple is the pair: processed images for a class, and the corresponding class.\n",
    "        \n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(dir):\n",
    "        raise Exception('load_directory(): root dir is not a directory: ' + dir)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # return object: set of collections and corresponding labels\n",
    "    collections = []\n",
    "    \n",
    "    # concurrency setup\n",
    "    pool = None\n",
    "    if concurrent > 1:\n",
    "        pool = mp.Pool(concurrent)\n",
    "\n",
    "    # Add directory seperator, if not already\n",
    "    if not dir.endswith('/'):\n",
    "        dir += '/'\n",
    "    # Iterate through all the subdirectories. These should be the classes (labels) and their corresponding contents\n",
    "    # the images.\n",
    "    subdirs = [dir + subdir for subdir in os.listdir(dir) ]\n",
    "    for subdir in subdirs:\n",
    "        # Process only subdirectories. For example, there maybe a license file under the root (parent) directory.\n",
    "        if os.path.isdir(subdir):\n",
    "            # Get all the files in the directory\n",
    "            files = [subdir + '/' + file for file in os.listdir(subdir)]\n",
    "            \n",
    "            # Subdirectory name is the label for these images (collection)\n",
    "            label = os.path.basename(subdir)\n",
    "            try:\n",
    "                # Load and process all the images for this collection (class)\n",
    "                if pool:\n",
    "                    pool.apply_async(load_files, (files, colorspace, resize, normal, flatten, datatype, label), callback=collections.append)\n",
    "                else:\n",
    "                    data, _, errors  = load_files(files, colorspace, resize, normal, flatten, datatype, label)\n",
    "                    \n",
    "                    # Assemble a list of each collection and its label\n",
    "                    collections.append( (data, label) )\n",
    "                if verbose: print(\"Data Preprocessed:\", subdir)\n",
    "            except Exception as e:\n",
    "                if verbose: print(\"ERROR: Unable to process images in Directory:\", subdir, e)\n",
    "        else:\n",
    "            if verbose: print(\"WARNING: Directory entry is not a folder:\", subdir)\n",
    "     \n",
    "    if pool:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "            \n",
    "    if verbose: print(\"Total Time:\", time.time() - start_time)\n",
    "    return collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
