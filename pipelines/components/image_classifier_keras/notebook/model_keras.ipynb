{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a Model for Computer Vision using Keras\n",
    "\n",
    "This *ML pipeline' constructs a Convolutional Neural Network (CNN) using Keras framework, as follows:\n",
    "\n",
    "        1. Configurable # of 2D Convolutional Layer, with configurable input size.\n",
    "        2. Max Pooling and Flattening Layer.\n",
    "        3. Configurable # of Neural Network layers, with configurable number of nodes.\n",
    "        4. Configurable # of dropout Layer, with configurable percentage.\n",
    "        5. Output Layer, with configurable number of outputs (classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras's Neural Network components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "# Kera's Convoluntional Neural Network components\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameters\n",
    "\n",
    "Use the `construct_cnn()` routine to construct the CNN, which is construct as:\n",
    "\n",
    "                    Convolutional -> Neural Network -> Output\n",
    "\n",
    "The `input_size` is the (height,width) shape of the preprocessed image data (machine learning ready data). For example, in the MNIST and EMMNIST datasets, the input size is (28,28).\n",
    "\n",
    "The `n_classes` is the number of classes to train the model for. Each class is a distinct object to recognize (e.g., a cat). The number of classes will be the number of nodes in the output layer of the neural network. For example, in the MNIST and EMMNIST datasets, the number of classes is 10 and 62 respectively.\n",
    "\n",
    "The `n_nodes` may either be a single integer value or a list of integer values. When specified as a single integer, the value is the number of nodes in the input layer of the neural network from the convolutional front-end, and there are no hidden layers.\n",
    "\n",
    "Otherwise, `n_nodes` is a list, the first list element is the number of nodes in the input layer of the neural network from the convolutional front-end. The remaining elements are the hidden layers, where the value of the element is the number of nodes in the corresponding hidden layer.\n",
    "\n",
    "The `dropout` is the percentage of dropout after the first layer of the neural network. If the value is 0, then there is no dropout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_cnn(input_shape, n_classes, n_filters=32, n_nodes=128, dropout=0):\n",
    "    \"\"\" Construct a CNN for Training and Inference.\n",
    "    Args:\n",
    "        input_shape: (tuple(int,int,int)) the 3D shape of the input vector.\n",
    "        n_classes  : (int) total number of classes.\n",
    "        n_filters  : (tuple(int,...)) number of filters per convolutional layer\n",
    "        n_nodes    : (tuple(int,...)) number of nodes per neural network layer.\n",
    "        dropout    : (float) Dropout rate between 0 and 1.\n",
    "    \n",
    "    Returns:\n",
    "        A compiled model.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    # Constructing a Feed Forward Neural Network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # make n_filters a tuple if a single int\n",
    "    if isinstance(n_filters, int):\n",
    "        n_filters = tuple([n_filters])\n",
    "\n",
    "    # Add a first convolutional front-end with 3x3 kernal\n",
    "    model.add(Conv2D(filters=n_filters[0], kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\n",
    "\n",
    "    # Add Remaining Convolutional layers\n",
    "    for ix in range(1, len(n_filters)):\n",
    "        if n_filters[ix] == True:\n",
    "            # Add max pooling layer\n",
    "            model.add(MaxPooling2D(pool_size=2))\n",
    "        else:\n",
    "            # Add next convolutional front-end with 3x3 kernal\n",
    "            model.add(Conv2D(filters=n_filters[ix], kernel_size=3, padding='same', activation='relu'))     \n",
    "    \n",
    "    # Add max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "              \n",
    "    # Flatten the output from the max pooling layer for input to the neural network\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # make n_nodes a tuple if a single integer\n",
    "    if isinstance(n_nodes, int):\n",
    "        n_nodes = tuple([n_nodes])\n",
    "        \n",
    "    # make dropout a tuple if a single integer\n",
    "    if isinstance(dropout, int) or isinstance(dropout, float):\n",
    "        # apply dropout to the first layer\n",
    "        dropout = [dropout]\n",
    "        # make remaining layers zero\n",
    "        for _ in range(1, len(n_nodes)):\n",
    "            dropout.append(0)\n",
    "        dropout = tuple(dropout)\n",
    "        \n",
    "    # Add layers\n",
    "    for ix in range(len(n_nodes)):\n",
    "        model.add(Dense(n_nodes[ix], activation='relu'))\n",
    "        # Add dropout if any\n",
    "        if dropout[ix] > 0:\n",
    "            model.add(Dropout(dropout[ix]))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    # Choice the loss function and optimizer and finish construcing the CNN\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function train_cnn() there are two ways of passing the train/test data.\n",
    "\n",
    "1. Unsplit: the train and test data are passed as combined data, in which case x_test and y_test are None. The function will then shuffle the combined data and then split the combined data into training and test based on the percent parameter.\n",
    "\n",
    "2. Split: the train and test data are already split, in which case x and y are the training data and x_test and y_test are the test data. The function does not shuffle or split the pre-split data, and the percent parameter is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def train_cnn(model, x, y, x_test=None, y_test=None, epochs=10, batch_size=32, percent=0.2, verbose=False, seed=113):\n",
    "    \"\"\" Train the model\n",
    "    Args:\n",
    "        model     : (model) The CNN model.\n",
    "        x         : (numpy.ndarray) The x portion (preprocessed image data) of the dataset.\n",
    "        y         : (numpy.ndarray) The y portion (labels) of the dataset.\n",
    "        x_test    : (numpy.ndarray) The x_test (if pre-split) portion of the dataset.\n",
    "        y_test    : (numpy.ndarray) The y_test (if pre-split) portion of the dataset.\n",
    "        epochs    : (int) The number of times to feed the entire dataset for training.\n",
    "        batch_size: (int) The mini-batch size.\n",
    "        percent   : (float) The percent of the dataset to use for test.\n",
    "        verbose   : (bool) Display (console) progress status.\n",
    "        seed      : (int) Seed for random shuffle before splitting.\n",
    "        learning_rate: (float) The learning rate.\n",
    "        \n",
    "    Returns:\n",
    "        The model accuracy after training and evaluation.\n",
    "    \n",
    "    Raises:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # one hot encode the labels\n",
    "    y = np_utils.to_categorical(y)\n",
    "    if y_test is not None:\n",
    "        y_test = np_utils.to_categorical(y_test)\n",
    "    \n",
    "    \n",
    "    # Images are grayscale. Keras expects shape to be (rows, height, width, channels) vs. (rows, height, width)\n",
    "    if len(x.shape) == 3:\n",
    "        x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "        if x_test is not None:\n",
    "            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)     \n",
    "            \n",
    "    # Ignore percent if data is already split\n",
    "    if x_test is not None:\n",
    "        percent = 0\n",
    "    \n",
    "    \n",
    "    # Calculate the number of elements which will be used as training data\n",
    "    train_size = int((1-percent) * len(x))\n",
    "    if verbose: print(\"Training Size:\", train_size)\n",
    "     \n",
    "    # Dataset is combined\n",
    "    if x_test is None:\n",
    "        # Randomly shuffle the data before splitting\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(x)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(y)\n",
    "\n",
    "        # split the data into Train and Test\n",
    "        X_train = x[:train_size]\n",
    "        Y_train = y[:train_size]\n",
    "        X_test  = x[train_size:]\n",
    "        Y_test  = y[train_size:]\n",
    "    # Dataset is presplit\n",
    "    else:\n",
    "        X_train = x\n",
    "        Y_train = y\n",
    "        X_test  = x_test\n",
    "        Y_test  = y_test\n",
    "\n",
    "    if verbose: verbose = 2\n",
    "        \n",
    "    # Train the model with the training data\n",
    "    model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=batch_size, shuffle=True, verbose=verbose)\n",
    "    \n",
    "    # Run the model with the test (evaluation) data\n",
    "    accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeGenerator(input_shape, n_classes, n_filters=32, n_nodes=128, dropout=0):\n",
    "    code = []\n",
    "    code.append(\"# Keras's Neural Network components\")\n",
    "    code.append(\"from keras.models import Sequential\")\n",
    "    code.append(\"from keras.layers import Dense, Dropout, Activation, Flatten\")\n",
    "    code.append(\"# Kera's Convoluntional Neural Network components\")\n",
    "    code.append(\"from keras.layers import Conv2D, MaxPooling2D\")\n",
    "    code.append(\"\")\n",
    "    code.append(\"def construct_cnn():\")\n",
    "    code.append(\"\\t# Constructing a Feed Forward Neural Network\")\n",
    "    code.append(\"\\tmodel = Sequential()\")\n",
    "    code.append(\"\")\n",
    "    \n",
    "    # make n_filters a tuple if a single int\n",
    "    if isinstance(n_filters, int):\n",
    "        n_filters = tuple([n_filters])\n",
    "        \n",
    "    # Add a first convolutional front-end with 3x3 kernal\n",
    "    code.append(\"\\tmodel.add(Conv2D(filters=\" + str(n_filters[0]) + \", kernel_size=3, padding='same', activation='relu', input_shape=\" + str(input_shape) + \"))\")\n",
    "\n",
    "    # Add Remaining Convolutional layers\n",
    "    for ix in range(1, len(n_filters)):\n",
    "        if n_filters[ix] == True:\n",
    "            # Add max pooling layer\n",
    "            code.append(\"\\tmodel.add(MaxPooling2D(pool_size=2))\")\n",
    "        else:\n",
    "            # Add next convolutional front-end with 3x3 kernal\n",
    "            code.append(\"\\tmodel.add(Conv2D(filters=\" + str(n_filters[ix]) + \", kernel_size=3, padding='same', activation='relu'))\")   \n",
    "                \n",
    "    # Add max pooling layer\n",
    "    code.append(\"\\tmodel.add(MaxPooling2D(pool_size=2))\")\n",
    "              \n",
    "    # Flatten the output from the max pooling layer for input to the neural network\n",
    "    code.append(\"\\tmodel.add(Flatten())\")\n",
    "    \n",
    "    # make n_nodes a tuple if a single integer\n",
    "    if isinstance(n_nodes, int):\n",
    "        n_nodes = tuple([n_nodes])\n",
    "        \n",
    "    # make dropout a tuple if a single integer\n",
    "    if isinstance(dropout, int) or isinstance(dropout, float):\n",
    "        # apply dropout to the first layer\n",
    "        dropout = [dropout]\n",
    "        # make remaining layers zero\n",
    "        for _ in range(1, len(n_nodes)):\n",
    "            dropout.append(0)\n",
    "        dropout = tuple(dropout)\n",
    "        \n",
    "    # Add layers\n",
    "    for ix in range(len(n_nodes)):\n",
    "        code.append(\"\\tmodel.add(Dense(\" + str(n_nodes[ix]) + \", activation='relu'))\")\n",
    "        # Add dropout if any\n",
    "        if dropout[ix] > 0:\n",
    "            code.append(\"\\tmodel.add(Dropout(\" + str(dropout[ix]) + \"))\")     \n",
    "\n",
    "    # Add the output layer\n",
    "    code.append(\"\\tmodel.add(Dense(\" + str(n_classes) + \", activation='softmax'))\")\n",
    "    \n",
    "    # Choice the loss function and optimizer and finish construcing the CNN\n",
    "    code.append(\"\\tmodel.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])\")\n",
    "    \n",
    "    code.append(\"\\treturn model\")\n",
    "    for line in code:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Simple Covnet\")\n",
    "#codeGenerator((28,28,1), 10, n_filters=(32, True, 64))\n",
    "\n",
    "#print(\"VGG16\")\n",
    "#codeGenerator( (224, 224, 3), 1000, n_filters=(64, 64, True, 128, 128, True, 256, 256, 256, True, 512, 512, 512, True, 512, 512, 512), n_nodes=(4096, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
