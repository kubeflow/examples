apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: tf-workflow-
spec:
  entrypoint: tests
  onExit: exit-handler
  # Parameters can be passed/overridden via the argo CLI.
  # To override the printed message, run `argo submit` with the -p option:
  # $ argo submit examples/arguments-parameters.yaml -p message="goodbye world"
  arguments:
    parameters:
    - name: datasets-image
      # default image
      value: gcr.io/constant-cubist-173123/tf_workflow:nan_workflow
    - name: tf-master # number of tf masters
      value: 1
    - name: tf-worker # number of tf workers
      value: 1
    - name: tf-ps # number of tf parameter servers
      value: 2
    - name: tf-model-image
      value: elsonrodriguez/mytfmodel:1.45
    - name: tf-server-image
      value: elsonrodriguez/mytfserver:1.6
    - name: tf-serving-image
      value: gcr.io/constant-cubist-173123/model-server:1.0
    - name: model-hidden-units
      value: 100
    - name: model-train-steps
      value: 200
    - name: model-batch-size
      value: 100
    - name: model-learning-rate
      value: 0.01
    - name: model-serving
      value: true
    - name: model-serving-servicetype
      value: ClusterIP
    - name: model-serving-ks-url
      value: github.com/elsonrodriguez/kubeflow/tree/serving-s3/kubeflow
    - name: model-serving-ks-tag
      value: serving-s3
    - name: job-name
      value: myjob
    - name: namespace
      value: default
    - name: s3-data-url
      value: s3://tfoperator/data/mnist/
    - name: s3-train-base-url
      value: s3://tfoperator/models
    - name: aws-endpoint-url
      value: https://s3.us-west-2.amazonaws.com
    - name: s3-endpoint
      value: s3.us-west-2.amazonaws.com
    - name: aws-region
      value: us-west-2
    - name: aws-secret
      value: aws-creds
  volumes:
  - name: training-data
    emptyDir: {}
  - name: training-output
  templates:
  - name: tests
    steps:
      - - name: download-dataset
          template: kvc
      - - name: get-workflow-info
          template: get-workflow-info
      - - name: train-model
          template: tf-train
          arguments:
            parameters:
            - name: nodeaffinity
              value: "{{steps.get-workflow-info.outputs.parameters.nodeaffinity}}"
            - name: hostpath
              value: "{{steps.get-workflow-info.outputs.parameters.hostpath}}"
      - - name: export-model
          template: tf-export
      - - name: serve-model
          template: tf-inference
          when: "{{workflow.parameters.model-serving}} == true"
      - - name: tensorboard
          template: tf-tensorboard
    # This is an example of how to do data conversion.
    # - - name: prepare-datasets
    #     template: download-and-convert-data
  - name: exit-handler
    steps:
      - - name: cleanup
          template: clean
  # - name: download-and-convert-data
  #   container:
  #     image: gcr.io/constant-cubist-173123/tf_workflow:nan_workflow
  #     imagePullPolicy: Always
  #     command: ["bash", "-c",  "python /notebooks/models/research/slim/download_and_convert_data.py --dataset_name=flowers --dataset_dir=/tmp/data"]
  #     outputs:
  #       artifacts:
  #       - name: training-data
  #         path: /tmp/data
  - name: kvc
    resource:
      action: apply
      successCondition: status.state == Running
      manifest: |
        apiVersion: aipg.intel.com/v1
        kind: VolumeManager
        metadata:
          name: mnist
          namespace: {{workflow.parameters.namespace}}
        spec:
          volumeConfigs:
            - id: "mnist-{{workflow.uid}}"
              replicas: {{workflow.parameters.tf-worker}}
              sourceType: "S3"
              sourceURL: "{{workflow.parameters.s3-data-url}}"
              AccessMode: "ReadWriteOnce"
              Capacity: 1Gi
              Labels:
                tfdata: mnist
              Options:
                awsCredentialsSecretName: {{workflow.parameters.aws-secret}}
  - name: get-workflow-info
    container:
      image: nervana/circleci:master
      imagePullPolicy: Always
      command: ["bash", "-c", "kubectl get volumemanager mnist -o json | jq -r '.status.volumes[].volumeSource.hostPath.path' | tee /tmp/hostpath; kubectl get volumemanager mnist -o json | jq '.status.volumes[].nodeAffinity' | tee /tmp/nodeaffinity; echo '{{workflow.parameters.s3-train-base-url}}/unfinished/{{workflow.parameters.job-name}}' | tr -d '[:space:]' > /tmp/s3-unfinished-url; echo '{{workflow.parameters.s3-train-base-url}}/exported/{{workflow.parameters.job-name}}/' | tr -d '[:space:]' > /tmp/s3-exported-url"]
    outputs:
      parameters:
      - name: hostpath
        valueFrom:
          path: /tmp/hostpath
      - name: nodeaffinity
        valueFrom:
          path: /tmp/nodeaffinity
      - name: s3-unfinished-url
        valueFrom:
          path: /tmp/s3-unfinished-url
      - name: s3-exported-url
        valueFrom:
          path: /tmp/s3-exported-url
  - name: tf-train
    inputs:
      parameters:
      - name: nodeaffinity
      - name: hostpath
    resource:
      action: apply
      # NOTE: need to detect master node complete
      successCondition: status.state == Succeeded
      manifest: |
        apiVersion: "kubeflow.org/v1alpha1"
        kind: "TFJob"
        metadata:
          name: {{workflow.parameters.job-name}}
          namespace: {{workflow.parameters.namespace}}
        spec:
          replicaSpecs:
            - replicas: {{workflow.parameters.tf-master}}
              tfReplicaType: MASTER
              template:
                spec:
                  affinity:
                    nodeAffinity:
                      {{inputs.parameters.nodeaffinity}}
                  serviceAccountName: tf-job-operator
                  containers:
                    - image: {{workflow.parameters.tf-model-image}}
                      name: tensorflow
                      imagePullPolicy: Always
                      args: ["python", "/opt/model.py", "--data_dir=/tmp/data", "--train_dir=/tmp/train", "--download=true", "--sync_replicas=true", "--hidden_units={{workflow.parameters.model-hidden-units}}", "--train_steps={{workflow.parameters.model-train-steps}}", "--batch_size={{workflow.parameters.model-batch-size}}", "--learning_rate={{workflow.parameters.model-learning-rate}}"]
                      volumeMounts:
                      - name: training-result
                        mountPath: /tmp/train
                      - name: training-data
                        mountPath: /tmp/data
                    - image: nervana/circleci:jose_wait_for_master
                      name: upload
                      env:
                      - name: POD_NAME
                        valueFrom:
                          fieldRef:
                            apiVersion: v1
                            fieldPath: metadata.name
                      - name: POD_NAMESPACE
                        valueFrom:
                          fieldRef:
                            apiVersion: v1
                            fieldPath: metadata.namespace
                      - name: AWS_ACCESS_KEY_ID
                        valueFrom:
                          secretKeyRef:
                            name: {{workflow.parameters.aws-secret}}
                            key: awsAccessKeyID
                      - name: AWS_SECRET_ACCESS_KEY
                        valueFrom:
                          secretKeyRef:
                            name: {{workflow.parameters.aws-secret}}
                            key: awsSecretAccessKey
                      - name: AWS_DEFAULT_REGION
                        value: {{workflow.parameters.aws-region}}
                      command: ['sh', '-c', "./bin/wait_for_master $POD_NAMESPACE $POD_NAME; aws --endpoint-url {{workflow.parameters.aws-endpoint-url}} s3 cp --recursive /tmp/train {{workflow.parameters.s3-train-base-url}}/unfinished/{{workflow.parameters.job-name}}/"]
                      volumeMounts:
                      - name: training-result
                        mountPath: /tmp/train
                  volumes:
                  - name: training-result
                    emptyDir: {}
                  - name: training-data
                    hostPath:
                      path: {{inputs.parameters.hostpath}}
                  restartPolicy: OnFailure
            - replicas: {{workflow.parameters.tf-worker}}
              tfReplicaType: WORKER
              template:
                spec:
                  affinity:
                    nodeAffinity:
                      {{inputs.parameters.nodeaffinity}}
                  serviceAccountName: tf-job-operator
                  containers:
                    - image: {{workflow.parameters.tf-server-image}}
                      name: tensorflow
                      imagePullPolicy: Always
                      volumeMounts:
                      - name: training-result
                        mountPath: /tmp/train
                      - name: training-data
                        mountPath: /tmp/data
                    - image: nervana/circleci:jose_wait_for_master
                      name: upload
                      env:
                      - name: POD_NAME
                        valueFrom:
                          fieldRef:
                            apiVersion: v1
                            fieldPath: metadata.name
                      - name: POD_NAMESPACE
                        valueFrom:
                          fieldRef:
                            apiVersion: v1
                            fieldPath: metadata.namespace
                      - name: AWS_ACCESS_KEY_ID
                        valueFrom:
                          secretKeyRef:
                            name: {{workflow.parameters.aws-secret}}
                            key: awsAccessKeyID
                      - name: AWS_SECRET_ACCESS_KEY
                        valueFrom:
                          secretKeyRef:
                            name: {{workflow.parameters.aws-secret}}
                            key: awsSecretAccessKey
                      - name: AWS_DEFAULT_REGION
                        value: {{workflow.parameters.aws-region}}
                      command: ['sh', '-c', "./bin/wait_for_master $POD_NAMESPACE $POD_NAME; aws --endpoint-url {{workflow.parameters.aws-endpoint-url}} s3 cp --recursive /tmp/train {{workflow.parameters.s3-train-base-url}}/unfinished/{{workflow.parameters.job-name}}/"]
                      volumeMounts:
                      - name: training-result
                        mountPath: /tmp/train
                  volumes:
                  - name: training-result
                    emptyDir: {}
                  - name: training-data
                    hostPath:
                      path: {{inputs.parameters.hostpath}}
                  restartPolicy: OnFailure
            - replicas: {{workflow.parameters.tf-ps}}
              tfReplicaType: PS
              template:
                spec:
                  containers:
                    - image: {{workflow.parameters.tf-server-image}}
                      name: tensorflow
                      imagePullPolicy: Always
                  restartPolicy: OnFailure
          terminationPolicy:
            chief:
              replicaIndex: 0
              replicaName: MASTER
  - name: tf-export
    resource:
      action: apply
      successCondition: status.phase == Succeeded
      failureCondition: status.phase == Failed
      manifest: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: exporter-{{workflow.parameters.job-name}}
        spec:
          restartPolicy: Never
          containers:
          - name: s3-download-unfinished
            image: volumecontroller/aws-cli:latest
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{workflow.parameters.aws-secret}}
                  key: awsAccessKeyID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{workflow.parameters.aws-secret}}
                  key: awsSecretAccessKey
            - name: AWS_ENDPOINT_URL
              value: {{workflow.parameters.aws-endpoint-url}}
            - name: AWS_DEFAULT_REGION
              value: {{workflow.parameters.aws-region}}
            command: ['sh', '-c', "aws s3 cp --recursive {{workflow.parameters.s3-train-base-url}}/unfinished/{{workflow.parameters.job-name}}/ /tmp/train && touch /tmp/download-done/done"]
            volumeMounts:
            - name: training-result
              mountPath: /tmp/train
            - name: download-done
              mountPath: /tmp/download-done
          - image: {{workflow.parameters.tf-model-image}}
            name: export
            imagePullPolicy: Always
            command: ['/bin/bash','-c', 'while [ ! -f /tmp/download-done/done ]; do sleep 5; done; ls -r /tmp/export/model; python /opt/export.py --checkpoint_dir=/tmp/train --output_dir=/tmp/export/model && touch /tmp/export-done/done']
            volumeMounts:
            - name: training-result
              mountPath: /tmp/train
            - name: download-done
              mountPath: /tmp/download-done
            - name: export-done
              mountPath: /tmp/export-done
            - name: export-result
              mountPath: /tmp/export
          - name: s3-upload-exported
            image: volumecontroller/aws-cli:latest
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{workflow.parameters.aws-secret}}
                  key: awsAccessKeyID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{workflow.parameters.aws-secret}}
                  key: awsSecretAccessKey
            - name: AWS_ENDPOINT_URL
              value: {{workflow.parameters.aws-endpoint-url}}
            - name: AWS_DEFAULT_REGION
              value: {{workflow.parameters.aws-region}}
            command: ['sh', '-c', 'while [ ! -f /tmp/export-done/done ]; do sleep 5; done; aws s3 cp --recursive /tmp/export/model/ {{workflow.parameters.s3-train-base-url}}/exported/{{workflow.parameters.job-name}}/']
            volumeMounts:
            - name: export-result
              mountPath: /tmp/export
            - name: export-done
              mountPath: /tmp/export-done
          volumes:
          - name: training-result
            emptyDir: {}
          - name: export-result
            emptyDir: {}
          - name: download-done
            emptyDir: {}
          - name: export-done
            emptyDir: {}
  - name: tf-tensorboard
    resource:
      action: apply
      manifest: |
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          labels:
            app: tensorboard-{{workflow.parameters.job-name}}
          name: tensorboard-{{workflow.parameters.job-name}}
          namespace: {{workflow.parameters.namespace}}
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: tensorboard-{{workflow.parameters.job-name}}
          template:
            metadata:
              labels:
                app: tensorboard-{{workflow.parameters.job-name}}
            spec:
              containers:
              - name: tensorboard-{{workflow.parameters.job-name}}
                image: elsonrodriguez/tensorboard:1.0
                imagePullPolicy: Always
                args:
                - {{workflow.parameters.s3-train-base-url}}/unfinished/{{workflow.parameters.job-name}}/
                env:
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      key: awsAccessKeyID
                      name: {{workflow.parameters.aws-secret}}
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      key: awsSecretAccessKey
                      name: {{workflow.parameters.aws-secret}}
                - name: AWS_REGION
                  value: {{workflow.parameters.aws-region}}
                - name: S3_REGION
                  value: {{workflow.parameters.aws-region}}
                - name: S3_USE_HTTPS
                  value: "true"
                - name: S3_VERIFY_SSL
                  value: "true"
                - name: S3_ENDPOINT
                  value: {{workflow.parameters.s3-endpoint}}
                ports:
                - containerPort: 6006
                  protocol: TCP
              dnsPolicy: ClusterFirst
              restartPolicy: Always
        ---
        apiVersion: v1
        kind: Service
        metadata:
          labels:
            app: tensorboard-{{workflow.parameters.job-name}}
          name: tensorboard-{{workflow.parameters.job-name}}
          namespace: {{workflow.parameters.namespace}}
        spec:
          ports:
          - port: 80
            protocol: TCP
            targetPort: 6006
          selector:
            app: tensorboard-{{workflow.parameters.job-name}}
          sessionAffinity: None
          type: LoadBalancer
  - name: tf-inference
    script:
      image: elsonrodriguez/ksonnet:0.8.0-test6
      command: ["/ksonnet-entrypoint.sh"]
      source: |
        MODEL_COMPONENT=serveMnist
        MODEL_PATH={{workflow.parameters.s3-train-base-url}}/exported/{{workflow.parameters.job-name}}
        MODEL_SERVER_IMAGE={{workflow.parameters.tf-serving-image}}

        ks init my-model-server
        cd my-model-server
        ks registry add kubeflow {{workflow.parameters.model-serving-ks-url}}
        ks pkg install kubeflow/tf-serving@{{workflow.parameters.model-serving-ks-tag}}
        ks env add default
        # TODO change mnist name to be specific to a job. Right now mnist name is required to serve the model.
        ks generate tf-serving ${MODEL_COMPONENT} --name=mnist-{{workflow.parameters.job-name}} --namespace={{workflow.parameters.namespace}} --model_path=${MODEL_PATH}
        ks param set ${MODEL_COMPONENT} model_server_image ${MODEL_SERVER_IMAGE}
        ks param set ${MODEL_COMPONENT} namespace {{workflow.parameters.namespace}}
        ks param set ${MODEL_COMPONENT} service_type {{workflow.parameters.model-serving-servicetype}}
        ks param set ${MODEL_COMPONENT} s3_create_secret false
        ks param set ${MODEL_COMPONENT} s3_secret_name {{workflow.parameters.aws-secret}}
        ks param set ${MODEL_COMPONENT} s3_secret_accesskeyid_key_name awsAccessKeyID
        ks param set ${MODEL_COMPONENT} s3_secret_secretaccesskey_key_name awsSecretAccessKey
        ks param set ${MODEL_COMPONENT} s3_aws_region {{workflow.parameters.aws-region}}
        ks param set ${MODEL_COMPONENT} s3_endpoint {{workflow.parameters.s3-endpoint}}
        ks apply default -c ${MODEL_COMPONENT}
      env:
      - name: SERVICE_ACCOUNT
        value: argo
  - name: clean
    container:
      image: nervana/circleci:master
      imagePullPolicy: Always
      command: ["bash", "-c", "kubectl delete tfjob {{workflow.parameters.job-name}} || true; kubectl delete pod exporter-{{workflow.parameters.job-name}} || true"]
