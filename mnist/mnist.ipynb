{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST E2E on Kubeflow on GKE\n",
    "\n",
    "* **This is a work in progress; this is not ready for users yet**\n",
    "\n",
    "This example guides you through the process of taking an example model, modifying it to run better within Kubeflow, and serving the resulting trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model\n",
    "\n",
    "There is a delta between existing distributed mnist examples and what's needed to run well as a TFJob.\n",
    "\n",
    "Basically, we must:\n",
    "\n",
    "1. Add options in order to make the model configurable.\n",
    "1. Use `tf.estimator.train_and_evaluate` to enable model exporting and serving.\n",
    "1. Define serving signatures for model serving.\n",
    "\n",
    "The resulting model is [model.py](model.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify we have a GCP account\n",
    "\n",
    "* The cell below checks that this notebook was spawned with credentials to access GCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from importlib import reload\n",
    "from oauth2client.client import GoogleCredentials\n",
    "credentials = GoogleCredentials.get_application_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "Import the libraries required to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200210 22:26:44 notebook_setup:26] pip installing fairing git+git://github.com/kubeflow/fairing.git@9b0d4ed4796ba349ac6067bbd802ff1d6454d015\n",
      "[I 200210 22:26:48 notebook_setup:34] Checkout kubeflow/tf-operator @9238906\n",
      "[I 200210 22:26:48 notebook_setup:37] Configure docker credentials\n",
      "[I 200210 22:26:49 notebook_setup:52] Adding /home/jovyan/git_tf-operator/sdk/python to python path\n"
     ]
    }
   ],
   "source": [
    "import notebook_setup\n",
    "reload(notebook_setup)\n",
    "notebook_setup.notebook_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure The Docker Registry For Kubeflow Fairing\n",
    "\n",
    "* In order to build docker images from your notebook we need a docker registry where the images will be stored\n",
    "* Below you set some variables specifying a [GCR container registry](https://cloud.google.com/container-registry/docs/)\n",
    "* Kubeflow Fairing provides a utility function to guess the name of your GCP project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client as k8s_client\n",
    "from kubeflow import fairing   \n",
    "from kubeflow.fairing import utils as fairing_utils\n",
    "from kubeflow.fairing.builders import append\n",
    "from kubeflow.fairing.deployers import job\n",
    "from kubeflow.fairing.preprocessors import base as base_preprocessor\n",
    "\n",
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Kubeflow fairing to build the docker image\n",
    "\n",
    "* You will use kubeflow fairing's kaniko builder to build a docker image that includes all your dependencies\n",
    "  * You use kaniko because you want to be able to run `pip` to install dependencies\n",
    "  * Kaniko gives you the flexibility to build images from Dockerfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(https://github.com/kubeflow/fairing/issues/426): We should get rid of this once the default \n",
    "# Kaniko image is updated to a newer image than 0.7.0.\n",
    "from kubeflow.fairing import constants\n",
    "constants.constants.KANIKO_IMAGE = \"gcr.io/kaniko-project/executor:v0.14.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow.fairing.builders import cluster\n",
    "\n",
    "# output_map is a map of extra files to add to the notebook.\n",
    "# It is a map from source location to the location inside the context.\n",
    "output_map =  {\n",
    "    \"Dockerfile.model\": \"Dockerfile\",\n",
    "    \"model.py\": \"model.py\"\n",
    "}\n",
    "\n",
    "\n",
    "preprocessor = base_preprocessor.BasePreProcessor(\n",
    "    command=[\"python\"], # The base class will set this.\n",
    "    input_files=[],\n",
    "    path_prefix=\"/app\", # irrelevant since we aren't preprocessing any files\n",
    "    output_map=output_map)\n",
    "\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200210 20:05:16 cluster:46] Building image using cluster builder.\n",
      "[W 200210 20:05:16 base:92] Dockerfile already exists in Fairing context, skipping...\n",
      "[I 200210 20:05:16 base:105] Creating docker context: /tmp/fairing_context_lmzqhmce\n",
      "[W 200210 20:05:16 base:92] Dockerfile already exists in Fairing context, skipping...\n",
      "[W 200210 20:05:17 manager:230] Waiting for fairing-builder-gxjqc-jbcjt to start...\n",
      "[W 200210 20:05:17 manager:230] Waiting for fairing-builder-gxjqc-jbcjt to start...\n",
      "[W 200210 20:05:17 manager:230] Waiting for fairing-builder-gxjqc-jbcjt to start...\n",
      "[I 200210 20:05:19 manager:236] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: logging before flag.Parse: E0210 20:05:24.082563       1 metadata.go:241] Failed to unmarshal scopes: invalid character 'h' looking for beginning of value\n",
      "\u001b[36mINFO\u001b[0m[0005] Resolved base name tensorflow/tensorflow:1.15.2-py3 to tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0005] Resolved base name tensorflow/tensorflow:1.15.2-py3 to tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0005] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "ERROR: logging before flag.Parse: E0210 20:05:24.418208       1 metadata.go:142] while reading 'google-dockercfg' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg\n",
      "ERROR: logging before flag.Parse: E0210 20:05:24.420332       1 metadata.go:159] while reading 'google-dockercfg-url' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg-url\n",
      "\u001b[36mINFO\u001b[0m[0005] Error while retrieving image from cache: getting file info: stat /cache/sha256:28b5f547969d70f825909c8fe06675ffc2959afe6079aeae754afa312f6417b9: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0005] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0006] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0006] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0006] Error while retrieving image from cache: getting file info: stat /cache/sha256:28b5f547969d70f825909c8fe06675ffc2959afe6079aeae754afa312f6417b9: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0006] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0006] Using files from context: [/kaniko/buildcontext/model.py]\n",
      "\u001b[36mINFO\u001b[0m[0006] Checking for cached layer gcr.io/jlewi-dev/fairing-job/mnist/cache:6802122184979734f01a549e1224c5f46a277db894d4b3e749e41ad1ca522bdf...\n",
      "\u001b[36mINFO\u001b[0m[0006] No cached layer found for cmd RUN chmod +x /opt/model.py\n",
      "\u001b[36mINFO\u001b[0m[0006] Unpacking rootfs as cmd RUN chmod +x /opt/model.py requires it.\n",
      "\u001b[36mINFO\u001b[0m[0030] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0044] Using files from context: [/kaniko/buildcontext/model.py]\n",
      "\u001b[36mINFO\u001b[0m[0044] ADD model.py /opt/model.py\n",
      "\u001b[36mINFO\u001b[0m[0044] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0044] RUN chmod +x /opt/model.py\n",
      "\u001b[36mINFO\u001b[0m[0044] cmd: /bin/sh\n",
      "\u001b[36mINFO\u001b[0m[0044] args: [-c chmod +x /opt/model.py]\n",
      "\u001b[36mINFO\u001b[0m[0044] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0046] ENTRYPOINT [\"/usr/bin/python\"]\n",
      "\u001b[36mINFO\u001b[0m[0046] No files changed in this command, skipping snapshotting.\n",
      "\u001b[36mINFO\u001b[0m[0046] CMD [\"/opt/model.py\"]\n",
      "\u001b[36mINFO\u001b[0m[0046] No files changed in this command, skipping snapshotting.\n",
      "\u001b[36mINFO\u001b[0m[0046] Pushing layer gcr.io/jlewi-dev/fairing-job/mnist/cache:6802122184979734f01a549e1224c5f46a277db894d4b3e749e41ad1ca522bdf to cache now\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ecb290db21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                  context_source=cluster.gcs_context.GCSContextSource())\n\u001b[1;32m     10\u001b[0m \u001b[0mcluster_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Built image {cluster_builder.image_tag}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "# Use a Tensorflow image as the base image\n",
    "# We use a custom Dockerfile \n",
    "cluster_builder = cluster.cluster.ClusterBuilder(registry=DOCKER_REGISTRY,\n",
    "                                                 base_image=\"\", # base_image is set in the Dockerfile\n",
    "                                                 preprocessor=preprocessor,\n",
    "                                                 image_name=\"mnist\",\n",
    "                                                 dockerfile_path=\"Dockerfile\",\n",
    "                                                 pod_spec_mutators=[fairing.cloud.gcp.add_gcp_credentials_if_exists],\n",
    "                                                 context_source=cluster.gcs_context.GCSContextSource())\n",
    "cluster_builder.build()\n",
    "logging.info(f\"Built image {cluster_builder.image_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a GCS Bucket\n",
    "\n",
    "* Create a GCS bucket to store our models and other results.\n",
    "* Since we are running in python we use the python client libraries but you could also use the `gsutil` command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200210 20:32:36 <ipython-input-37-c3f3efa8de59>:8] Creating bucket jlewi-dev-mnist\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "bucket = f\"{GCP_PROJECT}-mnist\"\n",
    "\n",
    "client = storage.Client()\n",
    "b = storage.Bucket(client=client, name=bucket)\n",
    "\n",
    "if not b.exists():\n",
    "    logging.info(f\"Creating bucket {bucket}\")\n",
    "    b.create()\n",
    "else:\n",
    "    logging.info(f\"Bucket {bucket} already exists\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training\n",
    "\n",
    "* We will train the model by using TFJob to run a distributed training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = f\"mnist-train-{uuid.uuid4().hex[:4]}\"\n",
    "num_ps = 1\n",
    "num_workers = 2\n",
    "model_dir = f\"gs://{bucket}/mnist\"\n",
    "export_path = f\"gs://{bucket}/mnist/export\" \n",
    "train_steps = 200\n",
    "batch_size = 100\n",
    "learning_rate = .01\n",
    "image = cluster_builder.image_tag\n",
    "\n",
    "train_spec = f\"\"\"apiVersion: kubeflow.org/v1\n",
    "kind: TFJob\n",
    "metadata:\n",
    "  name: {train_name}\n",
    "spec:\n",
    "  tfReplicaSpecs:\n",
    "    Ps:\n",
    "      replicas: {num_ps}\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          serviceAccount: default-editor\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            command:\n",
    "            - python\n",
    "            - /opt/model.py\n",
    "            - --tf-model-dir={model_dir}\n",
    "            - --tf-export-dir={export_path}\n",
    "            - --tf-train-steps={train_steps}\n",
    "            - --tf-batch-size={batch_size}\n",
    "            - --tf-learning-rate={learning_rate}\n",
    "            image: {image}\n",
    "            workingDir: /opt\n",
    "          restartPolicy: OnFailure\n",
    "    Chief:\n",
    "      replicas: 1\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          serviceAccount: default-editor\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            command:\n",
    "            - python\n",
    "            - /opt/model.py\n",
    "            - --tf-model-dir={model_dir}\n",
    "            - --tf-export-dir={export_path}\n",
    "            - --tf-train-steps={train_steps}\n",
    "            - --tf-batch-size={batch_size}\n",
    "            - --tf-learning-rate={learning_rate}\n",
    "            image: {image}\n",
    "            workingDir: /opt\n",
    "          restartPolicy: OnFailure\n",
    "    Worker:\n",
    "      replicas: 1\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          serviceAccount: default-editor\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            command:\n",
    "            - python\n",
    "            - /opt/model.py\n",
    "            - --tf-model-dir={model_dir}\n",
    "            - --tf-export-dir={export_path}\n",
    "            - --tf-train-steps={train_steps}\n",
    "            - --tf-batch-size={batch_size}\n",
    "            - --tf-learning-rate={learning_rate}\n",
    "            image: {image}\n",
    "            workingDir: /opt\n",
    "          restartPolicy: OnFailure\n",
    "\"\"\"           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training job\n",
    "\n",
    "* We could write the spec to a YAML file and then do `kubectl apply -f {FILE}`\n",
    "* Since we are running in jupyter we will use the Kubernetes python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client as k8s_client\n",
    "from kubernetes import config as k8s_config\n",
    "from kubeflow.tfjob.api import tf_job_client as tf_job_client_module\n",
    "\n",
    "tf_job_client = tf_job_client_module.TFJobClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception when calling CustomObjectsApi->create_namespaced_custom_object:         (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '7c265fd3-73f6-436a-b5d3-d874c7325aa2', 'Content-Type': 'application/json', 'Date': 'Mon, 10 Feb 2020 22:29:41 GMT', 'Content-Length': '250'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"tfjobs.kubeflow.org \\\"mnist-train-5a18\\\" already exists\",\"reason\":\"AlreadyExists\",\"details\":{\"name\":\"mnist-train-5a18\",\"group\":\"kubeflow.org\",\"kind\":\"tfjobs\"},\"code\":409}\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/git_tf-operator/sdk/python/kubeflow/tfjob/api/tf_job_client.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, tfjob, namespace)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFJOB_PLURAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         tfjob)\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/custom_objects_api.py\u001b[0m in \u001b[0;36mcreate_namespaced_custom_object\u001b[0;34m(self, group, version, namespace, plural, body, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_namespaced_custom_object_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/custom_objects_api.py\u001b[0m in \u001b[0;36mcreate_namespaced_custom_object_with_http_info\u001b[0;34m(self, group, version, namespace, plural, body, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                                         \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_request_timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                                         collection_formats=collection_formats)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    333\u001b[0m                                    \u001b[0mresponse_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                                    _return_http_data_only, collection_formats, _preload_content, _request_timeout)\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                      \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                      _request_timeout=_request_timeout)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    376\u001b[0m                                          \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                                          body=body)\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    265\u001b[0m                             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                             body=body)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kubernetes/client/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mApiException\u001b[0m: (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '7c265fd3-73f6-436a-b5d3-d874c7325aa2', 'Content-Type': 'application/json', 'Date': 'Mon, 10 Feb 2020 22:29:41 GMT', 'Content-Length': '250'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"tfjobs.kubeflow.org \\\"mnist-train-5a18\\\" already exists\",\"reason\":\"AlreadyExists\",\"details\":{\"name\":\"mnist-train-5a18\",\"group\":\"kubeflow.org\",\"kind\":\"tfjobs\"},\"code\":409}\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-00a5cc1a6ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf_job_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_job_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_job_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_tf-operator/sdk/python/kubeflow/tfjob/api/tf_job_client.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, tfjob, namespace)\u001b[0m\n\u001b[1;32m     71\u001b[0m       raise RuntimeError(\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m\"\u001b[0m\u001b[0mException\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mCustomObjectsApi\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mcreate_namespaced_custom_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m          %s\\n\" % e)\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception when calling CustomObjectsApi->create_namespaced_custom_object:         (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '7c265fd3-73f6-436a-b5d3-d874c7325aa2', 'Content-Type': 'application/json', 'Date': 'Mon, 10 Feb 2020 22:29:41 GMT', 'Content-Length': '250'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"tfjobs.kubeflow.org \\\"mnist-train-5a18\\\" already exists\",\"reason\":\"AlreadyExists\",\"details\":{\"name\":\"mnist-train-5a18\",\"group\":\"kubeflow.org\",\"kind\":\"tfjobs\"},\"code\":409}\n\n\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "tf_job_body = yaml.load(train_spec)\n",
    "tf_job = tf_job_client.create(tf_job_body, namespace=namespace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the job\n",
    "\n",
    "* We can use kubectl get the status of our job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: kubeflow.org/v1\n",
      "kind: TFJob\n",
      "metadata:\n",
      "  creationTimestamp: \"2020-02-10T20:57:05Z\"\n",
      "  generation: 1\n",
      "  name: mnist-train-5a18\n",
      "  namespace: kubeflow-jlewi\n",
      "  resourceVersion: \"64083\"\n",
      "  selfLink: /apis/kubeflow.org/v1/namespaces/kubeflow-jlewi/tfjobs/mnist-train-5a18\n",
      "  uid: e4b85f47-4c47-11ea-86b4-42010a8e01a3\n",
      "spec:\n",
      "  tfReplicaSpecs:\n",
      "    Chief:\n",
      "      replicas: 1\n",
      "      template:\n",
      "        metadata:\n",
      "          annotations:\n",
      "            sidecar.istio.io/inject: \"false\"\n",
      "        spec:\n",
      "          containers:\n",
      "          - command:\n",
      "            - python\n",
      "            - /opt/model.py\n",
      "            - --tf-model-dir=gs://jlewi-dev-mnist/mnist\n",
      "            - --tf-export-dir=gs://jlewi-dev-mnist/mnist/export\n",
      "            - --tf-train-steps=200\n",
      "            - --tf-batch-size=100\n",
      "            - --tf-learning-rate=0.01\n",
      "            image: gcr.io/jlewi-dev/fairing-job/mnist:8EB3617D\n",
      "            name: tensorflow\n",
      "            workingDir: /opt\n",
      "          restartPolicy: OnFailure\n",
      "          serviceAccount: default-editor\n",
      "    Ps:\n",
      "      replicas: 1\n",
      "      template:\n",
      "        metadata:\n",
      "          annotations:\n",
      "            sidecar.istio.io/inject: \"false\"\n",
      "        spec:\n",
      "          containers:\n",
      "          - command:\n",
      "            - python\n",
      "            - /opt/model.py\n",
      "            - --tf-model-dir=gs://jlewi-dev-mnist/mnist\n",
      "            - --tf-export-dir=gs://jlewi-dev-mnist/mnist/export\n",
      "            - --tf-train-steps=200\n",
      "            - --tf-batch-size=100\n",
      "            - --tf-learning-rate=0.01\n",
      "            image: gcr.io/jlewi-dev/fairing-job/mnist:8EB3617D\n",
      "            name: tensorflow\n",
      "            workingDir: /opt\n",
      "          restartPolicy: OnFailure\n",
      "          serviceAccount: default-editor\n",
      "    Worker:\n",
      "      replicas: 1\n",
      "      template:\n",
      "        metadata:\n",
      "          annotations:\n",
      "            sidecar.istio.io/inject: \"false\"\n",
      "        spec:\n",
      "          containers:\n",
      "          - command:\n",
      "            - python\n",
      "            - /opt/model.py\n",
      "            - --tf-model-dir=gs://jlewi-dev-mnist/mnist\n",
      "            - --tf-export-dir=gs://jlewi-dev-mnist/mnist/export\n",
      "            - --tf-train-steps=200\n",
      "            - --tf-batch-size=100\n",
      "            - --tf-learning-rate=0.01\n",
      "            image: gcr.io/jlewi-dev/fairing-job/mnist:8EB3617D\n",
      "            name: tensorflow\n",
      "            workingDir: /opt\n",
      "          restartPolicy: OnFailure\n",
      "          serviceAccount: default-editor\n",
      "status:\n",
      "  conditions:\n",
      "  - lastTransitionTime: \"2020-02-10T20:57:05Z\"\n",
      "    lastUpdateTime: \"2020-02-10T20:57:05Z\"\n",
      "    message: TFJob mnist-train-5a18 is created.\n",
      "    reason: TFJobCreated\n",
      "    status: \"True\"\n",
      "    type: Created\n",
      "  - lastTransitionTime: \"2020-02-10T20:57:07Z\"\n",
      "    lastUpdateTime: \"2020-02-10T20:57:07Z\"\n",
      "    message: TFJob mnist-train-5a18 is running.\n",
      "    reason: TFJobRunning\n",
      "    status: \"True\"\n",
      "    type: Running\n",
      "  replicaStatuses:\n",
      "    Chief:\n",
      "      active: 1\n",
      "    PS:\n",
      "      active: 1\n",
      "    Worker:\n",
      "      active: 1\n",
      "  startTime: \"2020-02-10T20:57:05Z\"\n"
     ]
    }
   ],
   "source": [
    "!kubectl get tfjobs -o yaml {train_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait For the Training Job to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    tf_job = crd_api.get_namespaced_custom_object(\n",
    "      KF_GROUP, TFJOB_VERSION, namespace, TFJOB_PLURAL, train_name)\n",
    "    \n",
    "    if not \"status\" in tf_job or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_job_client.wait_for_condition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lastTransitionTime': '2020-02-10T20:58:03Z',\n",
       " 'lastUpdateTime': '2020-02-10T20:58:03Z',\n",
       " 'message': 'TFJob mnist-train-5a18 successfully completed.',\n",
       " 'reason': 'TFJobSucceeded',\n",
       " 'status': 'True',\n",
       " 'type': 'Succeeded'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_job[\"status\"][\"conditions\"][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
