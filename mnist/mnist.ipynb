{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST E2E on Kubeflow on GKE\n",
    "\n",
    "This example guides you through:\n",
    "  \n",
    "  1. Taking an example TensorFlow model and modifying it to support distributed training\n",
    "  1. Serving the resulting model using TFServing\n",
    "  1. Deploying and using a web-app that uses the model\n",
    "  \n",
    "## Requirements\n",
    "\n",
    "  * You must be running Kubeflow 1.0 on GKE with IAP\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model\n",
    "\n",
    "There is a delta between existing distributed mnist examples and what's needed to run well as a TFJob.\n",
    "\n",
    "Basically, we must:\n",
    "\n",
    "1. Add options in order to make the model configurable.\n",
    "1. Use `tf.estimator.train_and_evaluate` to enable model exporting and serving.\n",
    "1. Define serving signatures for model serving.\n",
    "\n",
    "The resulting model is [model.py](model.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify we have a GCP account\n",
    "\n",
    "* The cell below checks that this notebook was spawned with credentials to access GCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from importlib import reload\n",
    "from oauth2client.client import GoogleCredentials\n",
    "credentials = GoogleCredentials.get_application_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "Import the libraries required to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip installing fairing git+git://github.com/kubeflow/fairing.git@9b0d4ed4796ba349ac6067bbd802ff1d6454d015\n",
      "Checkout kubeflow/tf-operator @9238906\n",
      "Configure docker credentials\n",
      "Adding /home/jovyan/git_tf-operator/sdk/python to python path\n"
     ]
    }
   ],
   "source": [
    "import notebook_setup\n",
    "reload(notebook_setup)\n",
    "notebook_setup.notebook_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k8s_util\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes import config as k8s_config\n",
    "from kubeflow.tfjob.api import tf_job_client as tf_job_client_module\n",
    "from IPython.core.display import display, HTML\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure The Docker Registry For Kubeflow Fairing\n",
    "\n",
    "* In order to build docker images from your notebook we need a docker registry where the images will be stored\n",
    "* Below you set some variables specifying a [GCR container registry](https://cloud.google.com/container-registry/docs/)\n",
    "* Kubeflow Fairing provides a utility function to guess the name of your GCP project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client as k8s_client\n",
    "from kubernetes.client import rest as k8s_rest\n",
    "from kubeflow import fairing   \n",
    "from kubeflow.fairing import utils as fairing_utils\n",
    "from kubeflow.fairing.builders import append\n",
    "from kubeflow.fairing.deployers import job\n",
    "from kubeflow.fairing.preprocessors import base as base_preprocessor\n",
    "\n",
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)\n",
    "namespace = fairing_utils.get_current_k8s_namespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Kubeflow fairing to build the docker image\n",
    "\n",
    "* You will use kubeflow fairing's kaniko builder to build a docker image that includes all your dependencies\n",
    "  * You use kaniko because you want to be able to run `pip` to install dependencies\n",
    "  * Kaniko gives you the flexibility to build images from Dockerfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(https://github.com/kubeflow/fairing/issues/426): We should get rid of this once the default \n",
    "# Kaniko image is updated to a newer image than 0.7.0.\n",
    "from kubeflow.fairing import constants\n",
    "constants.constants.KANIKO_IMAGE = \"gcr.io/kaniko-project/executor:v0.14.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow.fairing.builders import cluster\n",
    "\n",
    "# output_map is a map of extra files to add to the notebook.\n",
    "# It is a map from source location to the location inside the context.\n",
    "output_map =  {\n",
    "    \"Dockerfile.model\": \"Dockerfile\",\n",
    "    \"model.py\": \"model.py\"\n",
    "}\n",
    "\n",
    "\n",
    "preprocessor = base_preprocessor.BasePreProcessor(\n",
    "    command=[\"python\"], # The base class will set this.\n",
    "    input_files=[],\n",
    "    path_prefix=\"/app\", # irrelevant since we aren't preprocessing any files\n",
    "    output_map=output_map)\n",
    "\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building image using cluster builder.\n",
      "Creating docker context: /tmp/fairing_context_vnw2_2y3\n",
      "Dockerfile already exists in Fairing context, skipping...\n",
      "Waiting for fairing-builder-bck4p-crvnw to start...\n",
      "Waiting for fairing-builder-bck4p-crvnw to start...\n",
      "Waiting for fairing-builder-bck4p-crvnw to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: logging before flag.Parse: E0211 19:46:16.689300       1 metadata.go:241] Failed to unmarshal scopes: invalid character 'h' looking for beginning of value\n",
      "\u001b[36mINFO\u001b[0m[0002] Resolved base name tensorflow/tensorflow:1.15.2-py3 to tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0002] Resolved base name tensorflow/tensorflow:1.15.2-py3 to tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0002] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "ERROR: logging before flag.Parse: E0211 19:46:17.083059       1 metadata.go:142] while reading 'google-dockercfg' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg\n",
      "ERROR: logging before flag.Parse: E0211 19:46:17.094233       1 metadata.go:159] while reading 'google-dockercfg-url' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg-url\n",
      "\u001b[36mINFO\u001b[0m[0003] Error while retrieving image from cache: getting file info: stat /cache/sha256:28b5f547969d70f825909c8fe06675ffc2959afe6079aeae754afa312f6417b9: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0003] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0003] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0003] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0003] Error while retrieving image from cache: getting file info: stat /cache/sha256:28b5f547969d70f825909c8fe06675ffc2959afe6079aeae754afa312f6417b9: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0003] Downloading base image tensorflow/tensorflow:1.15.2-py3\n",
      "\u001b[36mINFO\u001b[0m[0003] Using files from context: [/kaniko/buildcontext/model.py]\n",
      "\u001b[36mINFO\u001b[0m[0003] Checking for cached layer gcr.io/jlewi-dev/fairing-job/mnist/cache:6802122184979734f01a549e1224c5f46a277db894d4b3e749e41ad1ca522bdf...\n",
      "\u001b[36mINFO\u001b[0m[0004] Using caching version of cmd: RUN chmod +x /opt/model.py\n",
      "\u001b[36mINFO\u001b[0m[0004] Skipping unpacking as no commands require it.\n",
      "\u001b[36mINFO\u001b[0m[0004] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0004] Using files from context: [/kaniko/buildcontext/model.py]\n",
      "\u001b[36mINFO\u001b[0m[0004] ADD model.py /opt/model.py\n",
      "\u001b[36mINFO\u001b[0m[0004] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0004] RUN chmod +x /opt/model.py\n",
      "\u001b[36mINFO\u001b[0m[0004] Found cached layer, extracting to filesystem\n",
      "\u001b[36mINFO\u001b[0m[0004] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0004] ENTRYPOINT [\"/usr/bin/python\"]\n",
      "\u001b[36mINFO\u001b[0m[0004] No files changed in this command, skipping snapshotting.\n",
      "\u001b[36mINFO\u001b[0m[0004] CMD [\"/opt/model.py\"]\n",
      "\u001b[36mINFO\u001b[0m[0004] No files changed in this command, skipping snapshotting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Built image gcr.io/jlewi-dev/fairing-job/mnist:E9B223C3\n"
     ]
    }
   ],
   "source": [
    "# Use a Tensorflow image as the base image\n",
    "# We use a custom Dockerfile \n",
    "cluster_builder = cluster.cluster.ClusterBuilder(registry=DOCKER_REGISTRY,\n",
    "                                                 base_image=\"\", # base_image is set in the Dockerfile\n",
    "                                                 preprocessor=preprocessor,\n",
    "                                                 image_name=\"mnist\",\n",
    "                                                 dockerfile_path=\"Dockerfile\",\n",
    "                                                 pod_spec_mutators=[fairing.cloud.gcp.add_gcp_credentials_if_exists],\n",
    "                                                 context_source=cluster.gcs_context.GCSContextSource())\n",
    "cluster_builder.build()\n",
    "logging.info(f\"Built image {cluster_builder.image_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a GCS Bucket\n",
    "\n",
    "* Create a GCS bucket to store our models and other results.\n",
    "* Since we are running in python we use the python client libraries but you could also use the `gsutil` command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bucket jlewi-dev-mnist already exists\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "bucket = f\"{GCP_PROJECT}-mnist\"\n",
    "\n",
    "client = storage.Client()\n",
    "b = storage.Bucket(client=client, name=bucket)\n",
    "\n",
    "if not b.exists():\n",
    "    logging.info(f\"Creating bucket {bucket}\")\n",
    "    b.create()\n",
    "else:\n",
    "    logging.info(f\"Bucket {bucket} already exists\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training\n",
    "\n",
    "* We will train the model by using TFJob to run a distributed training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = f\"mnist-train-{uuid.uuid4().hex[:4]}\"\n",
    "num_ps = 1\n",
    "num_workers = 2\n",
    "model_dir = f\"gs://{bucket}/mnist\"\n",
    "export_path = f\"gs://{bucket}/mnist/export\" \n",
    "train_steps = 200\n",
    "batch_size = 100\n",
    "learning_rate = .01\n",
    "image = cluster_builder.image_tag\n",
    "\n",
    "train_spec = f\"\"\"apiVersion: kubeflow.org/v1\n",
    "kind: TFJob\n",
    "metadata:\n",
    "  name: {train_name}  \n",
    "spec:\n",
    "  tfReplicaSpecs:\n",
    "    Ps:\n",
    "      replicas: {num_ps}\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          serviceAccount: default-editor\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            command:\n",
    "            - python\n",
    "            - /opt/model.py\n",
    "            - --tf-model-dir={model_dir}\n",
    "            - --tf-export-dir={export_path}\n",
    "            - --tf-train-steps={train_steps}\n",
    "            - --tf-batch-size={batch_size}\n",
    "            - --tf-learning-rate={learning_rate}\n",
    "            image: {image}\n",
    "            workingDir: /opt\n",
    "          restartPolicy: OnFailure\n",
    "    Chief:\n",
    "      replicas: 1\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          serviceAccount: default-editor\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            command:\n",
    "            - python\n",
    "            - /opt/model.py\n",
    "            - --tf-model-dir={model_dir}\n",
    "            - --tf-export-dir={export_path}\n",
    "            - --tf-train-steps={train_steps}\n",
    "            - --tf-batch-size={batch_size}\n",
    "            - --tf-learning-rate={learning_rate}\n",
    "            image: {image}\n",
    "            workingDir: /opt\n",
    "          restartPolicy: OnFailure\n",
    "    Worker:\n",
    "      replicas: 1\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          serviceAccount: default-editor\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            command:\n",
    "            - python\n",
    "            - /opt/model.py\n",
    "            - --tf-model-dir={model_dir}\n",
    "            - --tf-export-dir={export_path}\n",
    "            - --tf-train-steps={train_steps}\n",
    "            - --tf-batch-size={batch_size}\n",
    "            - --tf-learning-rate={learning_rate}\n",
    "            image: {image}\n",
    "            workingDir: /opt\n",
    "          restartPolicy: OnFailure\n",
    "\"\"\"           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training job\n",
    "\n",
    "* We could write the spec to a YAML file and then do `kubectl apply -f {FILE}`\n",
    "* Since we are running in jupyter we will use the Kubernetes python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_job_client = tf_job_client_module.TFJobClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tf_job_body = yaml.load(train_spec)\n",
    "tf_job = tf_job_client.create(tf_job_body, namespace=namespace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the job\n",
    "\n",
    "* We can use kubectl get the status of our job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get tfjobs -o yaml {train_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy TensorBoard\n",
    "\n",
    "* You will create a Kubernetes Deployment to run TensorBoard\n",
    "* TensorBoard will be accessible behind the Kubeflow IAP endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_name = \"mnist-tensorboard\"\n",
    "tb_deploy = f\"\"\"apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  labels:\n",
    "    app: mnist-tensorboard\n",
    "  name: {tb_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: mnist-tensorboard\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: mnist-tensorboard\n",
    "        version: v1\n",
    "    spec:\n",
    "      serviceAccount: default-editor\n",
    "      containers:\n",
    "      - command:\n",
    "        - /usr/local/bin/tensorboard\n",
    "        - --logdir={model_dir}\n",
    "        - --port=80\n",
    "        image: tensorflow/tensorflow:1.15.2-py3\n",
    "        name: tensorboard\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "\"\"\"\n",
    "tb_service = f\"\"\"apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  labels:\n",
    "    app: mnist-tensorboard\n",
    "  name: {tb_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  ports:\n",
    "  - name: http-tb\n",
    "    port: 80\n",
    "    targetPort: 80\n",
    "  selector:\n",
    "    app: mnist-tensorboard\n",
    "  type: ClusterIP\n",
    "\"\"\"\n",
    "\n",
    "tb_virtual_service = f\"\"\"apiVersion: networking.istio.io/v1alpha3\n",
    "kind: VirtualService\n",
    "metadata:\n",
    "  name: {tb_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  gateways:\n",
    "  - kubeflow/kubeflow-gateway\n",
    "  hosts:\n",
    "  - '*'\n",
    "  http:\n",
    "  - match:\n",
    "    - uri:\n",
    "        prefix: /mnist/{namespace}/tensorboard/\n",
    "    rewrite:\n",
    "      uri: /\n",
    "    route:\n",
    "    - destination:\n",
    "        host: {tb_name}.{namespace}.svc.cluster.local\n",
    "        port:\n",
    "          number: 80\n",
    "    timeout: 300s\n",
    "\"\"\"\n",
    "\n",
    "tb_specs = [tb_deploy, tb_service, tb_virtual_service]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_util.apply_k8s_specs(tb_specs, k8s_util.K8S_CREATE_OR_REPLACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access The TensorBoard UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = k8s_util.get_iap_endpoint() \n",
    "if endpoint:    \n",
    "    vs = yaml.safe_load(tb_virtual_service)\n",
    "    path= vs[\"spec\"][\"http\"][0][\"match\"][0][\"uri\"][\"prefix\"]\n",
    "    tb_endpoint = endpoint + path\n",
    "    display(HTML(f\"TensorBoard UI is at <a href='{tb_endpoint}'>{tb_endpoint}</a>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait For the Training Job to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_job = tf_job_client.wait_for_condition(train_name, expected_condition=[\"Succeeded\", \"Failed\"], namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Deploy the model using tensorflow serving\n",
    "* We need to create\n",
    "  1. A Kubernetes Deployment\n",
    "  1. A Kubernetes service\n",
    "  1. (Optional) Create a configmap containing the prometheus monitoring config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_name = \"mnist-model\"\n",
    "model_base_path = export_path\n",
    "\n",
    "# The web ui defaults to mnist-service so if you change it you will\n",
    "# need to change it in the UI as well to send predictions to the mode\n",
    "model_service = \"mnist-service\"\n",
    "\n",
    "deploy_spec = f\"\"\"apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  labels:\n",
    "    app: mnist\n",
    "  name: {deploy_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: mnist-model\n",
    "  template:\n",
    "    metadata:\n",
    "      # TODO(jlewi): Right now we disable the istio side car because otherwise ISTIO rbac will prevent the\n",
    "      # UI from sending RPCs to the server. We should create an appropriate ISTIO rbac authorization\n",
    "      # policy to allow traffic from the UI to the model servier.\n",
    "      # https://istio.io/docs/concepts/security/#target-selectors\n",
    "      annotations:        \n",
    "        sidecar.istio.io/inject: \"false\"\n",
    "      labels:\n",
    "        app: mnist-model\n",
    "        version: v1\n",
    "    spec:\n",
    "      serviceAccount: default-editor\n",
    "      containers:\n",
    "      - args:\n",
    "        - --port=9000\n",
    "        - --rest_api_port=8500\n",
    "        - --model_name=mnist\n",
    "        - --model_base_path={model_base_path}\n",
    "        - --monitoring_config_file=/var/config/monitoring_config.txt\n",
    "        command:\n",
    "        - /usr/bin/tensorflow_model_server\n",
    "        env:\n",
    "        - name: modelBasePath\n",
    "          value: {model_base_path}\n",
    "        image: tensorflow/serving:1.15.0\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        livenessProbe:\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 30\n",
    "          tcpSocket:\n",
    "            port: 9000\n",
    "        name: mnist\n",
    "        ports:\n",
    "        - containerPort: 9000\n",
    "        - containerPort: 8500\n",
    "        resources:\n",
    "          limits:\n",
    "            cpu: \"4\"\n",
    "            memory: 4Gi\n",
    "          requests:\n",
    "            cpu: \"1\"\n",
    "            memory: 1Gi\n",
    "        volumeMounts:\n",
    "        - mountPath: /var/config/\n",
    "          name: model-config\n",
    "      volumes:\n",
    "      - configMap:\n",
    "          name: {deploy_name}\n",
    "        name: model-config\n",
    "\"\"\"\n",
    "\n",
    "service_spec = f\"\"\"apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  annotations:    \n",
    "    prometheus.io/path: /monitoring/prometheus/metrics\n",
    "    prometheus.io/port: \"8500\"\n",
    "    prometheus.io/scrape: \"true\"\n",
    "  labels:\n",
    "    app: mnist-model\n",
    "  name: {model_service}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  ports:\n",
    "  - name: grpc-tf-serving\n",
    "    port: 9000\n",
    "    targetPort: 9000\n",
    "  - name: http-tf-serving\n",
    "    port: 8500\n",
    "    targetPort: 8500\n",
    "  selector:\n",
    "    app: mnist-model\n",
    "  type: ClusterIP\n",
    "\"\"\"\n",
    "\n",
    "monitoring_config = f\"\"\"kind: ConfigMap\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: {deploy_name}\n",
    "  namespace: {namespace}\n",
    "data:\n",
    "  monitoring_config.txt: |-\n",
    "    prometheus_config: {{\n",
    "      enable: true,\n",
    "      path: \"/monitoring/prometheus/metrics\"\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "model_specs = [deploy_spec, service_spec, monitoring_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_util.apply_k8s_specs(model_specs, k8s_util.K8S_CREATE_OR_REPLACE)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the mnist UI\n",
    "\n",
    "* We will now deploy the UI to visual the mnist results\n",
    "* Note: This is using a prebuilt and public docker image for the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_name = \"mnist-ui\"\n",
    "ui_deploy = f\"\"\"apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: {ui_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: mnist-web-ui\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: mnist-web-ui\n",
    "    spec:\n",
    "      containers:\n",
    "      - image: gcr.io/kubeflow-examples/mnist/web-ui:v20190112-v0.2-142-g3b38225\n",
    "        name: web-ui\n",
    "        ports:\n",
    "        - containerPort: 5000        \n",
    "      serviceAccount: default-editor\n",
    "\"\"\"\n",
    "\n",
    "ui_service = f\"\"\"apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  annotations:\n",
    "  name: {ui_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  ports:\n",
    "  - name: http-mnist-ui\n",
    "    port: 80\n",
    "    targetPort: 5000\n",
    "  selector:\n",
    "    app: mnist-web-ui\n",
    "  type: ClusterIP\n",
    "\"\"\"\n",
    "\n",
    "ui_virtual_service = f\"\"\"apiVersion: networking.istio.io/v1alpha3\n",
    "kind: VirtualService\n",
    "metadata:\n",
    "  name: {ui_name}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  gateways:\n",
    "  - kubeflow/kubeflow-gateway\n",
    "  hosts:\n",
    "  - '*'\n",
    "  http:\n",
    "  - match:\n",
    "    - uri:\n",
    "        prefix: /mnist/{namespace}/ui/\n",
    "    rewrite:\n",
    "      uri: /\n",
    "    route:\n",
    "    - destination:\n",
    "        host: {ui_name}.{namespace}.svc.cluster.local\n",
    "        port:\n",
    "          number: 80\n",
    "    timeout: 300s\n",
    "\"\"\"\n",
    "\n",
    "ui_specs = [ui_deploy, ui_service, ui_virtual_service]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_util.apply_k8s_specs(ui_specs, k8s_util.K8S_CREATE_OR_REPLACE)     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the  web UI\n",
    "\n",
    "* A reverse proxy route is automatically added to the Kubeflow IAP endpoint\n",
    "* The endpoint will be\n",
    "\n",
    "  ```\n",
    "  http:/${KUBEflOW_ENDPOINT}/mnist/${NAMESPACE}/ui/  \n",
    "  ```kubeflow-jlewi\n",
    "* You can get the KUBEFLOW_ENDPOINT\n",
    "\n",
    "  ```\n",
    "  KUBEfLOW_ENDPOINT=`kubectl -n istio-system get ingress envoy-ingress -o jsonpath=\"{.spec.rules[0].host}\"`\n",
    "  ```\n",
    "  \n",
    "  * You must run this command with sufficient RBAC permissions to get the ingress.\n",
    "  \n",
    "* If you have sufficient privileges you can run the cell below to get the endpoint if you don't have sufficient priveleges you can \n",
    "  grant appropriate permissions by running the command\n",
    "  \n",
    "   ```\n",
    "   kubectl create --namespace=istio-system rolebinding --clusterrole=kubeflow-view --serviceaccount=${NAMESPACE}:default-editor ${NAMESPACE}-istio-view\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = k8s_util.get_iap_endpoint() \n",
    "if endpoint:    \n",
    "    vs = yaml.safe_load(ui_virtual_service)\n",
    "    path= vs[\"spec\"][\"http\"][0][\"match\"][0][\"uri\"][\"prefix\"]\n",
    "    ui_endpoint = endpoint + path\n",
    "    display(HTML(f\"mnist UI is at <a href='{ui_endpoint}'>{ui_endpoint}</a>\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
