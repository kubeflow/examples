{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Ames Model\n",
    "\n",
    "Lightweight python components do not require you to build a new container image for every code change.\n",
    "They're intended to use for fast iteration in notebook environment.\n",
    "\n",
    "#### Building a lightweight python component\n",
    "To build a component just define a stand-alone python function and then call kfp.components.func_to_container_op(func) to convert it to a component that can be used in a pipeline.\n",
    "\n",
    "There are several requirements for the function:\n",
    "* The function should be stand-alone. It should not use any code declared outside of the function definition. Any imports should be added inside the main function. Any helper functions should also be defined inside the main function.\n",
    "* The function can only import packages that are available in the base image. If you need to import a package that's not available you can try to find a container image that already includes the required packages. (As a workaround you can use the module subprocess to run pip install for the required package.)\n",
    "* If the function operates on numbers, the parameters need to have type hints. Supported types are ```[int, float, bool]```. Everything else is passed as string.\n",
    "* To build a component with multiple output values, use the typing.NamedTuple type hint syntax: ```NamedTuple('MyFunctionOutputs', [('output_name_1', type), ('output_name_2', float)])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'Ames'\n",
    "KFP_PACKAGE = 'https://storage.googleapis.com/ml-pipeline/release/0.1.20/kfp.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://storage.googleapis.com/ml-pipeline/release/0.1.20/kfp.tar.gz\n",
      "\u001b[?25l  Downloading https://storage.googleapis.com/ml-pipeline/release/0.1.20/kfp.tar.gz (67kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 16.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.25,>=1.15 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<=9.0.0,>=8.0.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (9.0.0)\n",
      "Collecting PyJWT>=1.6.4 (from kfp==0.1.20)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.20) (1.6.3)\n",
      "Collecting requests_toolbelt>=0.8.0 (from kfp==0.1.20)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting kfp-server-api<0.1.19,>=0.1.18 (from kfp==0.1.20)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/76/8d966b2bbd753aee0ae913973aa89b0eeda3cc574f7a4cbb0fdfcbbd43fb/kfp-server-api-0.1.18.2.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<0.30dev,>=0.29.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.20) (0.29.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.20) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.20) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (0.56.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (40.9.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.20) (1.12.2)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.20) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.20) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.20) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.20) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.0->kfp==0.1.20) (1.5.9)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.0->kfp==0.1.20) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.0->kfp==0.1.20) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.20) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp==0.1.20) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth>=1.6.1->kfp==0.1.20) (0.4.5)\n",
      "Building wheels for collected packages: kfp, kfp-server-api\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-n5h6li2g/wheels/ae/bb/02/32b1356ee756181099d8f1b0950ac6567cb2b38e71b48f02e8\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/8f/ed/14/ac11fdf68438c1e501cbb05ca138f13a9319c0f5ba373ea00b\n",
      "Successfully built kfp kfp-server-api\n",
      "Installing collected packages: PyJWT, requests-toolbelt, kfp-server-api, kfp\n",
      "  Found existing installation: kfp 0.1\n",
      "    Uninstalling kfp-0.1:\n",
      "      Successfully uninstalled kfp-0.1\n",
      "Successfully installed PyJWT-1.7.1 kfp-0.1.20 kfp-server-api-0.1.18.2 requests-toolbelt-0.9.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the SDK\n",
    "!pip3 install $KFP_PACKAGE --upgrade\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "import kfp.gcp as gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function that just add two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated service account credentials for: [label-issues-0409-user@code-search-demo.iam.gserviceaccount.com]\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth activate-service-account --key-file=${GOOGLE_APPLICATION_CREDENTIALS} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": [
     "fairing-include"
    ]
   },
   "outputs": [],
   "source": [
    "#Define a Python function\n",
    "def train(train_data: str, model_file: str) -> str:\n",
    "    '''Train the model'''\n",
    "    test_size=0.25\n",
    "    n_estimators = 50\n",
    "    learning_rate = 0.1\n",
    "        \n",
    "    import joblib\n",
    "    import re\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from xgboost import XGBRegressor\n",
    "    def split_gcs_uri(gcs_uri):\n",
    "        \"\"\"Split a GCS URI into bucket and path.\"\"\"\n",
    "        GCS_REGEX = re.compile(\"gs://([^/]*)(/.*)?\")\n",
    "        m = GCS_REGEX.match(gcs_uri)\n",
    "        bucket = m.group(1)\n",
    "        path = \"\"\n",
    "        if m.group(2):\n",
    "            path = m.group(2).lstrip(\"/\")\n",
    "        return bucket, path\n",
    "    \n",
    "    train_bucket_name, train_path = split_gcs_uri(train_data)\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    storage_client = storage.Client()\n",
    "    train_bucket = storage_client.get_bucket(train_bucket_name)   \n",
    "    train_blob = train_bucket.blob(train_path)\n",
    "\n",
    "    train_blob.download_to_filename(\"/tmp/data.csv\")\n",
    "        \n",
    "    import pandas as pd\n",
    "\n",
    "    data = pd.read_csv(\"/tmp/data.csv\")\n",
    "    \n",
    "    model_bucket_name, model_path = split_gcs_uri(model_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "    y = data.SalePrice\n",
    "    X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X.values,\n",
    "                                                        y.values,\n",
    "                                                        test_size=test_size,\n",
    "                                                        shuffle=False)\n",
    "\n",
    "    imputer = SimpleImputer()\n",
    "    train_X = imputer.fit_transform(train_X)\n",
    "    test_X = imputer.transform(test_X)\n",
    "    \n",
    "    def train_model(train_X,\n",
    "                train_y,\n",
    "                test_X,\n",
    "                test_y,\n",
    "                n_estimators,\n",
    "                learning_rate):\n",
    "        \"\"\"Train the model using XGBRegressor.\"\"\"\n",
    "        model = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "        model.fit(train_X,\n",
    "                train_y,\n",
    "                early_stopping_rounds=40,\n",
    "                eval_set=[(test_X, test_y)])\n",
    "\n",
    "        print(\"Best RMSE on eval: {0} with {1} rounds\".format(\n",
    "                   model.best_score,\n",
    "                   model.best_iteration+1))\n",
    "        return model\n",
    "\n",
    "    def eval_model(model, test_X, test_y):\n",
    "        \"\"\"Evaluate the model performance.\"\"\"\n",
    "        predictions = model.predict(test_X)\n",
    "        print(\"mean_absolute_error=%.2f\", mean_absolute_error(predictions, test_y))\n",
    "\n",
    "    def save_model(model, model_file):\n",
    "        \"\"\"Save XGBoost model for serving.\"\"\"\n",
    "        joblib.dump(model, model_file)\n",
    "        print(\"Model export success: {0}\".format(model_file))\n",
    "    \n",
    "    model = train_model(train_X,\n",
    "                          train_y,\n",
    "                          test_X,\n",
    "                          test_y,\n",
    "                          n_estimators,\n",
    "                          learning_rate)\n",
    "\n",
    "    eval_model(model, test_X, test_y)\n",
    "    save_model(model, \"/tmp/model.dat\")\n",
    "\n",
    "    model_bucket = storage_client.get_bucket(model_bucket_name)   \n",
    "    model_blob = model_bucket.blob(model_path)\n",
    "    \n",
    "    model_blob.upload_from_filename(\"/tmp/model.dat\")\n",
    "    \n",
    "    print(\"Model uploaded to {0}\".format(model_file))\n",
    "    return model_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training locally\n",
    "if False:\n",
    "    train(\"gs://code-search-demo_ames/data/ames_dataset/train.csv\", \"gs://code-search-demo_ames/output/model-local.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the function to a pipeline operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the docker image built by fairing as the base image\n",
    "image = \"gcr.io/code-search-demo/fairing-job/fairing-job:1FE4890C\"\n",
    "train_op = comp.func_to_container_op(train, base_image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pipeline\n",
    "Pipeline function has to be decorated with the `@dsl.pipeline` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kubernetes import client as k8s_client\n",
    "@dsl.pipeline(\n",
    "   name='Training pipeline',\n",
    "   description='A pipeline that trains the model.'\n",
    ")\n",
    "def train_pipeline(\n",
    "   train_data=\"gs://code-search-demo_ames/data/ames_dataset/train.csv\",\n",
    "   model_file=\"gs://code-search-demo_ames/output/hello-world1.txt\",\n",
    "):      \n",
    "    train_task = train_op(train_data, model_file).apply(gcp.use_gcp_secret('user-gcp-sa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = train_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/b96e70b2-e551-442d-9e04-ac35551cd07c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/f0e4f7d9-7870-11e9-8964-42010a8e00ff\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "arguments = {\"train_data\": \"gs://code-search-demo_ames/data/ames_dataset/train.csv\",\n",
    "             \"model_file\": \"gs://code-search-demo_ames/output/hello-world1.txt\"}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "\n",
    "#vvvvvvvvv This link leads to the run information page. (Note: There is a bug in JupyterLab that modifies the URL and makes the link stop working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous completed run https://label-issues-0409.endpoints.code-search-demo.cloud.goog/pipeline/#/runs/details/1bc82d20-7870-11e9-8964-42010a8e00ff\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous completed run https://label-issues-0409.endpoints.code-search-demo.cloud.goog/pipeline/#/runs/details/1bc82d20-7870-11e9-8964-42010a8e00ff\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
